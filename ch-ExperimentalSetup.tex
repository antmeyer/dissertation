\chapter{EXPERIMENTAL SETUP}
\label{ch:experi}
\section{Introduction}
This chapter will describe the experimental setup, i.e., the steps I took to prepare for and run the experiments. This discussion
is divided into two main parts: The first (section~\ref{sec:datasource} concerns the extraction of the input data, including a description of the original data source. The second (section~\ref{sec:expvars)} discusses the experimental variables. The experimental variables comprise two broad categories, namely the \emph{data representation} (i.e., orthographic vs. transcriptional) and the \emph{feature types}. These are discussed in detail in section\ref{sec:features}. 

%description of the original data source and the extraction the particular eps I took to extract and format the particular dnput data sets, and (2) choosing the experimental variables an in order to  It will describe experiments' 
%data source as well as the steps taken to extract the datasets and reformat them as necessary. 
%% according 
%to the needs of this study. It will also then motivate and enumerate the experimental 
%(i.e., independent) variables addressed by this study.

Multimorph takes as input any list of words. The words can be of any
language, although Multimorph does expect the input strings to be composed
of alphabetic symbols. It also assumes that each symbol will be atomic rather 
than composite. 
For example the symbol \textsf{\textipa{\.*k}} can be represented in Unicode either 
as a sequence of two code points, namely \texttt{U+006B, U+0323} 
(where \texttt{U+0323}
corresponds to the dot), or as the \emph{single} code point \texttt{+U1E33}. 
Multimorph 
expects the latter in its present form. I mention this because the data source 
expresses
such characters in the former way, i.e., as sequences of code points. I thus had
to map the sequences onto atomic code points such as \texttt{U+0323} 
for \textsf{\textipa{\.*k}}.

When Multimorph reads the input wordlist, 
it maps each word onto
a sequence of 1s and 0s called a \emph{feature vector}, 
where each 1 or 0 is the value of a
particular feature. 
%We shall address the matter of features  
%in section~\ref{sec:features} below. 
Features often follow some sort of template such as $\alpha$@[x], i.e., `character $\alpha$ occurs at position $x$' where $x$ is a member of an appropriate range of integers. This feature template can instantiated as many different specific features, and thus it constitutes a feature family (or category, type, etc.). The question of which feature types (as well as which particular feature instantiations) is one of this dissertation's research questions. 
%constitute some of this study's main experimental 
%variables. We shall thus be particularly 
%concerned with the question of what features to test.

\section{Data Source: The Berman Longitudinal Corpus}
\label{sec:datasource}
\subsection{Corpus Overview}
\label{sec:corpus-overview}
The input datasets (i.e., wordlists) were extracted 
from the \ac{BLC}, \citep{berman-weissenborn:1991}. 
The \ac{BLC} is part of the Hebrew section of the 
CHILDES Corpus \citep{macwhinney:2000a}, a corpus 
of transcribed conversations between young children 
and adults. I chose the \ac{BLC} because 
it is one of the few sources of \emph{transcribed} Modern Hebrew. 
Most other Hebrew sources consist of printed material, 
such as newspaper text, and thus is orthographic 
rather than transcribed. The Hebrew alphabet has no 
dedicated letters for vowels, and thus Hebrew 
orthography is largely without vowels. I wanted data 
that in which the vowels were 
fully represented. Another advantage of the \ac{BLC} is that 
it is quite extensive; I am unaware of larger source of 
transcribed Modern Hebrew. 

Each file in the \ac{BLC} is the transcription of a 
particular session. The participants, who are identified 
in each file's header, can include, for example, the parents,
 other relatives, such as a grandmother, 
the researcher (or \emph{investigator}) conducting the 
session, and most importantly the child him or herself, 
who is called the \emph{target child}. All participants 
were native speakers of Modern Hebrew. The \ac{BLC} comprises 
the transcriptions of many individual recording sessions. 
Each child's sessions were conducted over a period of 
12 to 19 months. Each child was between 16 and 21 months 
old when his/her recording sessions began, and between 
28 to 39 months old ($2\frac{1}{3}$ to $3\frac{1}{4}$ 
years old) when they ended.

Figure~\ref{fig:excerpt} shows an excerpt from the \ac{BLC}. 
This excerpt contains two utterances, one spoken by the 
target child (CHI), and the other by the child's mother (MOT).
\begin{figure}[ht]
\vspace{10pt}
\label{fig:excerpt}
\caption{\emph{Excerpt from the Berman Longitudinal Corpus (BLC).}
*The BLC's gloss `tools' is a generic translation of the Hebrew \textit{kel\'{i}m}; 
the context here seems to suggest `dishes' 
as a better translation. That is, `tools (for eating)' = `dishes.' } 
\vspace{-12pt}\begin{tabbing}
\small
\hspace{0.6in} \= \hspace{0.6in} \=  \hspace{0.5in} \= \hspace{0.6in} \= \hspace{3.4in} \kill
\textsf{*MOT:} \> \textsf{ma} \> \textsf{\textipa{P}\a'{i}ma\textipa{P}} \> \textsf{\textipa{P}o\textipa{\.*s}\a'{a}} \>  \textsf{ba\# mi\textipa{\.*t}b\a'{a}x ?} \\
\> \textit{What [is]} \> \textit{Mom} \> \textit{doing} \> \textit{in.\textsc{def}+kitchen ?} \\
\textsf{\%mor:} \> \textsf{que|ma=what n|\textipa{P}\a'{i}ma\textipa{P}\&gen:fm\&num:sg\&stat:free=mother} \\
 \> \textsf{part|\textipa{P}a\textipa{\.*s}\a'{a}\&root:\textipa{P}\textipa{\.*s}y\&ptn:qal\&gen:fm\&num:sg-\a'{a}=do} \\
   \> \textsf{prep|be~det|ha n|mi\textipa{\.*t}b\a'{a}x\&gen:ms\&num:sg\&stat:unsp=kitchen ?}\\
\textsf{\%gra:} \>	\textsf{1|3|ANONAGR 2|3|AAGR 3|0|ROOT 4|3|MPRE 5|6|MDET 6|4|APREP 7|3|PUNCT}\\
\textsf{CHI:} \> \textsf{rox\a'{e}cet} \> \textsf{kel\a'{i}m .}\\
		\> \textit{Washing} \> \textit{dishes .}*  \\
\textsf{\%mor:} \> \textsf{part|rax\a'{a}c\&root:rxc\&ptn:qal\&gen:fm\&num:sg-et=wash} \\ 
    \>  \textsf{n|kli}\&\textsf{gen:ms\&num:pl\&pl:masc:match\&stat:free-\a'{i}m=tool .} \\ 
\textsf{\%gra:} \> \textsf{1|0|ROOT 2|1|ANONAGR 3|1|PUNCT}
\end{tabbing}
\end{figure}
The first utterance in figure~\ref{fig:excerpt} is that of mother,
who says, ``What is Mom doing in the kitchen?" The child
then replies \textsf{[rox\a'{e}cet kel\a'{i}m]}, `Washing dishes.' 
I have inserted these English words as glosses in italics as additional 
rows of text beneath the rows of transcribed words in figure~\ref{fig:excerpt}. 
Note these two extra rows do not appear. 
in the actual \ac{BLC}.

The asterisk (*) preceding the labels CHI and \textsf{MOT} 
indicates that these tiers are \emph{main} tiers, i.e.,  
utterance tiers. Each utterance is accompanied by two 
additional tiers, 
namely, a morphological tier, labeled \textsf{\%mor}, 
and a syntactic (or grammatical) tier, labeled \textsf{\%gra}. 
The syntactic tier is not relevant to the present thesis,
so we shall not refer to it further. The morphological tier 
has a hierarchical structure. At the highest level, it consists of a 
series of space-delimited morphological analyses, 
There is exactly one analysis for each word in the main tier.  
Each \emph{individual} morphological analysis consists
of \textit{morphosyntactic properties}. These are delimited by the 
ampersand symbol (\textsf{\&}). Morphosyntactic properties are 
generally expressed as feature-value pairs of the 
form \textsf{\textit{feature}:\textit{value}}, e.g., 
\textsf{gen:fm} `gender: feminine.' 

In the remainder of this section, we shall first discuss the 
\ac{BLC}'s unique transcription system, a system that 
honors Hebrew orthography as much as it does its spoken 
pronunciation. We shall then discuss some key aspects of 
the \ac{BLC}'s morphological annotation scheme. The 
transcription system is important for the present study 
because the features
depend on the alphabet in which the data is represented.
 The morphological annotation 
is significant because  the BLC's morphological annotations must 
serve as raw material for creation of  the intrinsic evaluation's 
gold-standard categories (see chapter~\ref{ch:eval}).

% such that a col typically 
%a given morphological analysis are morphosyntactic properties, usually composed
%of a \textit{feature} and \textit{value}, with a colon separating the former
%from the latter, e.g., \textsf{gen:fm} `gender: feminine.'
%The morphosyntactic properties are delimited by the ampersand symbol (\textsf{\&}).
%categories, many of expressed as feature-value pairs, e.g., \textsf{gen:fm}.  

\subsection{Transcription System}
\label{sec:transcription}
The \ac{BLC}'s transcription system eludes simple one-word 
characterizations such as ``orthographic,"
``phonetic," or ``phonemic." It is in fact a hybrid system, drawing
both from phonetics and orthography \citep{albert-et-al:2013}. 
It is a transcription system in some ways and a transliteration 
system in others. It is a transcription system in that it has 
five dedicated vowel symbols, 
namely \{a, e, i, o, u\}, each of which matches one of the 
vowels in Modern Hebrew's five-vowel inventory. 
At the same time, however, 
it is a \emph{transliteration} system in that it is sensitive to 
orthographic distinctions that no longer correspond
The present consonantal alphabet of Hebrew originated in the 
language's classical period, with each 
consonantal grapheme corresponding to 
a distinct consonantal phoneme in Classical Hebrew \citep{rendsburg:1997}. The alphabet itself
has remained largely unchanged 
into the present day \citep{weinberg:1975, ravid:2005}; i.e. it has the same letters as it 
did in antiquity. The phonemic inventory 
of Hebrew, however, has changed. Thus, the correspondence 
between the graphemes of the Hebrew
alphabet and the phonemes of Modern Hebrew is far from perfect. 
The consonant inventory of Modern Hebrew
has undergone a number of neutralizations, leaving 
Modern Hebrew with a smaller inventory of consonant phonemes than
Classical Hebrew had. %Hebrew had in the Biblical period (i.e., the older part 
of the Classical period). 
The mapping 
from consonantal graphemes in the Hebrew alphabet
to Modern Hebrew consonantal phonemes is therefore many-to-one.

%Moreover, because each grapheme originally corresponded to a distinct phoneme, the Hebrew alphabet is a direct reflection of the (consonantal) phonemic inventory of Classical Hebrew (CITE). Each letter corresponds to to a sound (or group of allophones) that was actually
%produced in speech in the classical period. Thus, when we mention of a sound or phoneme of Classical Hebrew in the following discussion, we refer to the ancient sound or phoneme that was originally associated with a particular grapheme of the Hebrew alphabet. We are assuming that the correspondence between Hebrew graphemes and Classical Hebrew phonemes was basically one-to-one.  

%However, the mapping between the alphabet's graphemes and the Modern Hebrew phonemes is certainly not one-to-one
In its rendering of consonants, the \ac{BLC}'s transcriptional system 
favors orthography over actual pronunciation \citep{albert-et-al:2013}.
It honors a number of historical distinctions that have preserved in the orthography, 
i.e., the alphabet and 
spelling conventions, but neutralized or otherwise lost in spoken Modern Hebrew. 
Table~\ref{tab:phon-neut} compares 
(reconstructed) Classical Hebrew phonemes, which are taken to be in a one-to-one 
correspondence with the letters of 
the Hebrew alphabet, Modern Hebrew speech sounds, and transcription symbols 
from the \ac{BLC}. Notice that the
the Modern Hebrew column has the fewest distinctions.

\begin{table}[ht]
\centering
\caption{Transcription System of the Berman Longitudinal Corpus}
\label{table:alphabet}
\subtable[Consonants\label{subtab:trans-cons}]{
\setlength{\extrarowheight}{8pt}
\begin{tabular}{c c c c c c c c c c c c c}
\hline %\hline                      
\begin{cjhebrew}'\end{cjhebrew} & \begin{cjhebrew}b\end{cjhebrew} & \begin{cjhebrew}g\end{cjhebrew} & \begin{cjhebrew}d\end{cjhebrew} 
& \begin{cjhebrew}h\end{cjhebrew} & \begin{cjhebrew}w\end{cjhebrew} & \begin{cjhebrew}z\end{cjhebrew}& \begin{cjhebrew}.h\end{cjhebrew}
& \begin{cjhebrew}.t\end{cjhebrew} & \begin{cjhebrew}y\end{cjhebrew} & \begin{cjhebrew}k|\end{cjhebrew} & \begin{cjhebrew}l\end{cjhebrew} 
&\begin{cjhebrew}m|\end{cjhebrew}\\ 
\textipa{P} & b/v & g & d 
& h & w & z & x 
& \textsubdot{t} & y & k/\textsubdot{k} & l & m \\[12pt]
           \begin{cjhebrew}n|\end{cjhebrew} & \begin{cjhebrew}s\end{cjhebrew} & \begin{cjhebrew}`\end{cjhebrew} 
           & \begin{cjhebrew}p|\end{cjhebrew} & \begin{cjhebrew}.s\end{cjhebrew} & \begin{cjhebrew}q\end{cjhebrew} & \begin{cjhebrew}r\end{cjhebrew} 
           & \begin{cjhebrew},s\end{cjhebrew}/\begin{cjhebrew}+s\end{cjhebrew}
           & \begin{cjhebrew}t\end{cjhebrew} & & \begin{cjhebrew}z\end{cjhebrew}$^\prime$ & \begin{cjhebrew}g\end{cjhebrew}$^\prime$ & \begin{cjhebrew}.s|\end{cjhebrew}$^\prime$ \\
	  n & s & \textipa{Q} 
	  & p/f & c & q & r & \v{s}/\textsubdot{s} 
	  & t & &  \v{z} & \textipa{J} & \c{c} \\
\hline
\end{tabular}
}
\subtable[Vowels\label{subtab:trans-vowels}]{
\setlength{\extrarowheight}{8pt}
\begin{tabular}{c c c c c}
\hline
a & e & i & o & u \\
\'a & \'e & \'i & \'o & \'u \\
\hline
\end{tabular}
}
\end{table}

The orthography of Modern Hebrew thus preserves the shadows of 
lost Classical Hebrew phonemes, as it were. 
Similarly, many morphophonological processes in Modern Hebrew
preserve residues of Classical Hebrew phonotactics and phonological processes. 
That is, even though the triggering contexts of these Classical Hebrew processes 
have been obscured or altogether lost due to sound changes, 
many have nonetheless been revived as fully-fledged components of Modern Hebrew. 
For example, in Classical Hebrew, the consonants \begin{cjhebrew}.h\end{cjhebrew} 
(\textit{\textipa{\textcrh{et}}}) and \begin{cjhebrew}`\end{cjhebrew}
(\textit{`ayin}) were both pharyngeal consonants; the former 
was a voiceless fricative (IPA \textipa{[\textcrh]}), and the latter a 
voiced stop (IPA \textipa{[Q]}). There was a process in Classical Hebrew 
whereby the [+low] vowel \textipa{[a]} was inserted between 
a [-low] vowel and a pharyngeal consonant to
mediate the transition between the [-low] vowel and the 
[+low] pharyngeal. This process is illustrated in table~\ref{tab:a-insertion}. 

\begin{table}[h]
\centering
\caption{\emph{a}-insertion before historical pharyngeals}\vspace{3pt}
\label{tab:a-insertion}
\setlength{\extrarowheight}{8pt}
\begin{tabular}{l l c c c}
\hline\hline
 & Classical Hebrew  & Modern Hebrew   &  \ac{BLC}  & Gloss \\
\hline
a. & \textipa{kot\'eB}  & \textipa{kot\'ev} & \textipa{kot\'ev} & `writes(s), writing' \\
b. & \textipa{bor\'e\textbf{a}\textcrh} & \textipa{bor\'e\textbf{a}x} & \textipa{bor\'e\textbf{a}x} & `escape(s), escaping'  \\
c. & \textipa{yod\'e\textbf{a}Q} & \textipa{yod\'e\textbf{a}} & \textipa{yod\'e\textbf{a}Q} & `know(s), knowing' \\\hline
\end{tabular}
\end{table}

Modern Hebrew, however, has no pharyngeals, having 
inherited its consonantal inventory 
largely from central and eastern European languages 
\citep{montoya:2014}. 
In Modern Hebrew, \textipa{[\textcrh]} 
is pronounced as a voiceless velar fricative 
(IPA \textipa{[x]}), and \textit{`ayin} 
is usually not pronounced at all. It has become 
phonologically 
equivalent to the historical glottal stop 
\begin{cjhebrew}'\end{cjhebrew} 
(\textit{'alef}). Both \begin{cjhebrew}'\end{cjhebrew} and 
\begin{cjhebrew}`\end{cjhebrew} 
are sometimes realized as glottal stops, but are 
often not pronounced at all, 
especially in fast speech \citep{matras-and-schiff:2005,berman:1985}. 
Nevertheless, Modern Hebrew has maintained the pre-pharyngeal 
\textit{a}-insertion process, as though the graphemes 
\begin{cjhebrew}`\end{cjhebrew} (\textit{`ayin}) and 
\textit{\textipa{\textcrh{et}}} still corresponded 
to phonological pharyngeals. This is shown in table~\ref{tab:a-insertion}:
In row (c), column Modern Hebrew, the \textit{a} is inserted 
even though the historical *\textipa{\textrevglotstop} 
(\textit{`ayin}) sound has vanished. In fact, no sound remains in this 
word-final position, not even a glottal stop for most 
speakers. The inserted \textit{a} thus ends up being the 
word's final phonological segment. And yet it is not the final segment
in the \ac{BLC}'s transcription, namely \textipa{yod\'eaQ} in row (c). 
The \ac{BLC} includes the grapheme \begin{cjhebrew}`\end{cjhebrew} 
(\textit{`ayin}) in the form of the transcriptional 
symbol \textipa{[\textrevglotstop]}, as though it
were an actual speech sound.
\begin{table}[h]
\centering 
\setlength{\extrarowheight}{8pt}
\begin{tabular}{l c c c}
\hline\hline
IPA & Orthography & BLC & Gloss  \\
\hline
    \textipa{[yad\'{a}]} &  \begin{cjhebrew}`dy\end{cjhebrew}  & \textipa{yad\'{a}Q} & `(he) knew' \\
    \textipa{[yad\'{a}]} &  \begin{cjhebrew}hdy\end{cjhebrew}  & \textipa{yad\'{a}h} &  `her hand' \\
\hline
\end{tabular}
\caption{Ambiguity arising from the loss of consonantal distinctions.}
\label{tab:yada} 
\end{table}

Such a hybrid system offers both advantages and disadvantages to a 
\ac{ULM} system like Multimorph. 
On the one hand, the inclusion of such``lost" consonants as 
\begin{cjhebrew}`\end{cjhebrew} 
(\textit{`ayin}) provides a system with additional and potentially 
quite valuable information. 
Phonemic mergers can obscure category memberships and thus 
create ambiguity. For instance, 
the forms for `(he) knew' and `her hand' in  table~\ref{tab:yada}
have identical pronunciations in Modern Hebrew, as indicated 
by their identical \ac{IPA} transcriptions
in \ref{tab:yada}. And yet they are different. 
The former is a 3ms past-tense verb of the 
\emph{qal} binyan. Its root consists of the \emph{three}
consonants \textit{\textipa{y-d-Q}}, which one must 
know in order 
to connect this verb to derivationally related words. 
The second \textipa{[yad\`{a}]} 
in table~\ref{tab:yada} is the noun \textit{yad} plus 
the 3fs possessive suffix 
\textit{-a(h)}, the final \emph{h} of which is not articulated. 
Because the \ac{BLC}'s transcriptional system preserves 
certain consonants and 
inter-consonant distinctions, it preserves information and 
thus reduces ambiguity. 
This is probably going to be advantageous to a \ac{ULM} 
system, even if the preserved 
information is not entirely accurate vis-\`{a}-vis Modern Hebrew 
pronunciation.

On the other hand, the inclusion of these non-Modern 
sounds means that more features are necessary to describe 
words. More features results in longer processing times. 
A larger number of features can also decrease accuracy 
if the additional features are not useful. 
In addition, increasing the number of symbols does not 
always help to clarify true relationships; sometimes it 
obscures them. For example, The BLC's transcriptions 
represent the spirantization of the certain oral obstruents; 
in particular, /b/ $\to$ v, /p/ $\to$ f, and /k/ $\to$ \textsubdot{k} 
in the context
Vowel \_\_. Hence, the \textit{b} in the root \textit{k-t-b} 
(`write') often surfaces as [v], as in, e.g., \textipa{\textit{katavti}} 
`I wrote', and 
\textipa{\textit{yi{\.*k}t\'ov}} `he will write', which exhibits 
two altered characters. Multimorph would see \textit{\textipa{\.*k}} 
and \textit{k} as 
entirely different symbols, not at allophones
of the same phoneme. The same would be true for \textit{b} 
and \textit{v}.  

%\begin{cjhebrew}yd`\end{cjhebrew}
%For the purposes of learning Hebrew morphology, this is probably useful information. 
%The more information the better, Dawg.
%For example, the presence of the phantom \textipa{Q} 
%probably makes it easier to identify the root 
%$\surd$y-d-\textipa{Q}

The grapheme \begin{cjhebrew}`\end{cjhebrew} (\textit{`ayin}) is not the only 
grapheme to have 
lost its ancient phonemic affiliation. 
The graphemes \begin{cjhebrew}.t\end{cjhebrew} 
(\textit{\textipa{\.*te\.*t}}), \begin{cjhebrew}s\end{cjhebrew} 
(\textit{\textipa{same\.*k}}), corresponded to emphatic, i.e., 
pharyngealized, consonants in ancient 
Hebrew, i.e. pharyngealized versions of [s] of [t], most likely 
\ref{matras-and-schiff:2005}.
Modern Hebrew, however, lacks pharyngealized consonants just as 
it lacks pharyngeals. 
The consonant \begin{cjhebrew}q\end{cjhebrew} (\textit{qof}, 
IPA \textipa{[q]}) was uvular and 
possibly pharyngealized in Classical Hebrew, but in Modern Hebrew, 
it has merged with the velar voiceless stop
\begin{cjhebrew}k|\end{cjhebrew} (\textit{kaf}, IPA \textipa{[k]}).
%Thus, 
%as the \emph{emphatic consonants}, were once associated with pharyngealized phonemes, but now they are pronounced simply as [s] and [t]. 
Similarly, the pronunciations (or affiliated phonemes) of 
\textit{\textipa{same\.*k}} and \textit{\textipa{\.*te\.*t}} 
have merged with those of \textit{sin} and \textit{tav} respectively, 
 so that \textit{\textipa{same\.*k}} and \textit{\textipa{sin}} 
 are both pronounced as [s], and \textit{\textipa{\.*te\.*t}} and 
 \textit{tav} as [t]. But whereas the phonemic inventory of 
 Modern Hebrew has lost distinctions, the Hebrew writing system has preserved sever inter-consonantal distinctions.

\begin{table}[ht]
\centering 
\setlength{\extrarowheight}{9pt}
\begin{tabular}{l c c c c }
\hline\hline
\multirow{2}{*}{Heb. Letter} & Special &  \multicolumn{2}{c}{IPA} & \multirow{2}{*}{\ac{BLC}}\\\cline{3-4}
    & Context & BH  & Modern Hebrew & \\
\hline
\begin{cjhebrew}'\end{cjhebrew} ('alef) & &  \textipa{P} & -- & \textit{\textsf{\textipa{P}}} \\
\begin{cjhebrew}`\end{cjhebrew} (`ayin) & &\textipa{Q} & -- & \textit{\textsf{\textipa{Q}}} \\
\begin{cjhebrew}q\end{cjhebrew} (qof )& & \textipa{q} & \textsf{\textipa{k}} & 
\textit{\textsf{\textipa{q}}} \\
\multirow{2}{*}{\begin{cjhebrew}k|\end{cjhebrew} (kaf)} & \multirow{2}{*}{Vowel\_} &
\textipa{k} & \textsf{\textipa{k}} & \textit{\textsf{\textipa{k}}} \\
		        & & \textipa{x} &\textsf{\textipa{x}} & \textit{\textsf{\textipa{\.*k}}} \\
 \begin{cjhebrew}x\end{cjhebrew} (\textipa{\textsubdot{h}et}) & &\textipa{\textcrh} & \textsf{\textipa{x}} & \textit{\textsf{\textipa{x}}} \\
 \begin{cjhebrew}s\end{cjhebrew} (\textipa{same\.*k}) & & ? &  \textsf{\textipa{s}} & \textit{\textsf{\textipa{s}}} \\
  \begin{cjhebrew},s\end{cjhebrew} (\textipa{sin}) & & \textipa{s}  &  \textsf{\textipa{s}} & \textit{\textsf{\textipa{\.*s}}} \\
 \begin{cjhebrew}.t\end{cjhebrew} (\textipa{\.*te\.*t}) & & ? &  \textsf{\textipa{t}} & \textit{\textsf{\textipa{\.*t}}} \\
  \multirow{2}{*}{\begin{cjhebrew}t\end{cjhebrew} (\textipa{tav})} & \multirow{2}{*}{Vowel\_} & \textipa{t} &  \textsf{\textipa{t}} & \textit{\textsf{\textipa{t}}} \\
&  & \textipa{T} &  \textsf{\textipa{t}} & \textit{\textsf{\textipa{t}}} \\
 \multirow{2}{*}{\begin{cjhebrew}b\end{cjhebrew} (bet)} & \multirow{2}{*}{Vowel\_} & \textipa{b} & \textsf{\textipa{b}} & \textit{\textsf{\textipa{b}}} \\
 &      	  & \textipa{B} & \textsf{\textipa{v}} & \textit{\textsf{\textipa{v}}} \\
 \begin{cjhebrew}w\end{cjhebrew} (\textipa{waw}) & & \textipa{w} & \textsf{\textipa{v}} & \textit{\textsf{\textipa{v}}} \\
\hline
\end{tabular}
\label{tab:phon-neut} 
\caption{Correspondences between Hebrew orthography, speech sounds (past and present), and the \ac{BLC}'s transcriptional system}
\end{table}

\subsection{Morphological Annotation}
For our purposes, the most salient aspects the \ac{BLC}'s morphological 
annotation are those relevant to the tasks of
\begin{itemize}
\item extracting unified word tokens, each completely free of internal morphological 
delimiters or any other annotative device
\item extracting each word's corresponding morphological analysis from the 
\textsf{\%mor} tier, maintaining the one-to-one
correspondence between words and morphological analyses. 
\end{itemize} %are those that \citep{albert-et-al:2012}.
The morphological analyses themselves essentially lists of morphological categories, 
i.e., lists of simple feature-value pairs.
The following is a \ac{BLC} morphological analysis after undergoing the transformations 
described in section~\ref{sec:extr}
\begin{exe} 
\ex \label{ex:finished}
\begin{tabbing}
\hspace{0.8in} \= \hspace{5.5in} \kill
\textsf{matxilim} \> \textsf{\textbf{matxil+im}\$\$part\&root:txl\&ptn:hifil\&gen:ms\&num:pl}\, \\
\> \textsf{\textbf{matxil+im}\$\$adj\&root:txl\&ptn:tbd\&gen:ms\&num:pl}
\end{tabbing}
\end{exe}
Note that there two separate analyses in (\ref{ex:finished}), a result of ambiguity. 
Note also that each analysis is preceded by a segmentation (in boldface). 
In cases of ambiguity, i.e., of multiple analyses, each analysis gets its own 
segmentation, even though the segmentations may be identical.

\paragraph{Prefixal clitics.} In Hebrew, many functional words are 
\textit{prefixal clitics}; that is, they attach to content 
words as prefixes. They include the definite article \textit{ha-}, the prepositions 
\textit{le-} `to,' \textit{be-} `be,' \textit{ke-} `like/as,' and \textit{me-} 
`from,' the  complementizer/relativizer \textit{\v{s}e-} `that/which,' and the 
conjunction \textit{we-} `and.' For example,  in
\textsf{wehay\'eled} (`and the boy'), the prefixes \textit{we} and \textit{ha} 
are attached as clitics to \textit{y\'eled}, 
so that the whole is regarded as a single word. The 
\ac{BLC} tokenizes these clitics, separating them from the 
main (content) word, and adding the number symbol (`\texttt{\#}') to 
the end of each prefixal clitic: \textsf{wehay\'eled} 
would be transcribed as \textsf{we\# ha\# y\'eled}.
\begin{exe}\label{ex:preclitics}
	\ex
	\textsf{we\#\, \v{s}e\# me\textipa{Q}arbev\'im} \\ 
	\textsf{conj|we conj:subor|\v{s}e\, part|\textipa{P}irb\'ev\&root:\textipa{Q}rbb\&ptn:piel\&gen:ms\&num:pl} 
\end{exe}

\paragraph{Demarcation of inflectional affixes.}
Past tense verbs take inflectional suffixes. Future-tense verbs take both inflectional prefixes and suffixes. 
Nominals, where inflection
is concerned, take only suffixes. The `\#' and `-' symbols are used to separate inflectional
affixes from the stem's morphological analysis; the `\#' used in the case of prefixes, `-' in the
case of suffixes, as in the following:

\begin{exe}
\ex \begin{tabbing} \label{ex:pre:v:suf}
\hspace{0.6in} \= \hspace{5.5in} \kill
\textsf{*Classical HebrewI:} \> \textsf{tirt\a'{u} .} \\
\textsf{\%mor:} \> \textbf{\textsf{ti}\#}\textsf{v|ra\textipa{P}\a'{a}\&root:r\textipa{P}y\&ptn:qal\&tense:fut\&pers:2\&
\textbf{gen:unsp\&num:pl-\a'{u}}=see}
\end{tabbing}
\end{exe}

\paragraph{Compound and bound nouns}
Construct-state nouns are labeled either as ``\textsf{stat:bound}'' 
or ``\textsf{stat:comp}'' (i.e.,`compound'). 
These two labels correspond to the same sort of phonological form, 
 so I collapsed them into a single label, namely 
``\textsf{stat:cstr}'' (for `construct state').

\subsection{Anomalous Forms}\label{sec:anomolous}

Even though the \ac{BLC} contains a good deal of adult speech, it also, 
of course, contains child speech, which  
can be rife with anomalies (anomalies relative to adult speech, that is). 
And while such anomalies are interesting if one is studying language acquisition 
in children, they are not helpful where the present study is concerned. It 
was there for necessary to ``correct'' such anomalous forms where it was 
possible to do so, and discard them where it was not. Toward this end, 
the \ac{BLC}'s annotation conventions proved to be a great help.

\paragraph{Forms to be replaced}
The \ac{BLC} deals with anomalous forms through a special 
annotative device consisting of a set square brackets, with the left bracket 
accompanied
by a colon, i.e., \textsf{[: \textit{corrected-form} ]}. Sometimes these brackets 
are followed by another set
of brackets. This latter set, if present, most frequently contains an asterisk 
(`*$\tau$') where $tau$ may be empty, or it may specify some error category. 
In the \ac{BLC}, it is most frequently empty, as in (\ref{ex:repl2}). 
According to the CHILDES manual \citep{macwhinney:2000b}, the purpose 
of the ``\textsf{[*$\tau$])}'' 
is to specify that an anomalous form is 
indeed erroneous rather than merely non-standard. 
However, this distinction between 
\textsf{[: \textit{corrected-form} ]} and 
\textsf{[: \textit{corrected-form} ] [*{$\tau$}])} is not always manifest in \ac{BLC}.

For example, in (\ref{ex:repl1}), the anomalous 
form \textsf{patux} 
(the `\textsf{@c} ' indicates a child-created form); 
the anomaly is an absent \textit{a} before the \textit{x}, thus violating 
a morphophonemic process 
whereby \textit{a} is inserted before pharyngeals, a process that was inherited 
from Classical Hebrew, even though Modern Hebrew no longer has pharyngeals (see \ref{tab:a-insertion}).
In (\ref{ex:repl2}), the error is essentially that the pre-\textit{\textipa{P}} 
\textit{a} is absent. The glottal stop
associated with the grapheme \begin{cjhebrew}'\end{cjhebrew} (\textit{'alef}) 
is typically not articulated in Modern Hebrew \citep{montoya:2014}. The distinction
between the two is not entirely clear.

In any case, however, the distinction, if there is one, is not important for our purposes. 
Either way, we want to replace the anomalous form with the form enclosed in 
(the first pair of) brackets (see (\ref{ex:brackets})). We can just discard the \textsf{[*$\tau$]} 
if it is present, regardless of what $\tau$ is.

\begin{exe}
\label{ex:brackets}
\ex \begin{xlist} 
   \ex\label{ex:repl1} \begin{tabbing}  
	\hspace{0.6in} \= \hspace{5.5in} \kill
	\textsf{*Classical HebrewI:} \> \textsf{po ye\v{s} patux@c \textbf{[: pat\a'{u}ax]} d\a'{e}let .}
	\end{tabbing}
     \ex\label{ex:repl2} \begin{tabbing}
	\hspace{0.6in} \= \hspace{5.5in} \kill
	\textsf{*Classical HebrewI:} \> \textsf{tikri \,\textbf{[: tiqre\textipa{P}\a'{i}]}\, \textbf{[*]}\, 
	sip\a'{u}r\, d\a'{o}da\, Orly .} \\
	\textsf{\%mor:} \> \textsf{ti\#v|qar\a'{a}\textipa{P}\&root:qr\textipa{P}\&ptn:qal\&tense:fut\&pers:2\&gen:fm\&num:sg-\a'{i}=read} \\
                    \> \textsf{n|sip\a'{u}r\&gen:ms\&num:sg\&stat:unsp } \\
                    \> \textsf{n|dod\&gen:fm\&num:sg\&stat:free-a=uncle/aunt} \textsf{n:prop|Orly .}
	\end{tabbing}
   \end{xlist}
\end{exe}

\paragraph{Dropped sounds}
Adults produce anomalous or non-standard speech, too. In (\ref{ex:dropped}), for instance, the investigator 
has dropped the 
\emph{n} from the infinitive form 
\textsf{li\textbf{(n)}s\'oa\textipa{Q}} (`to ride, drive, travel'), 
which is of the root n.s.\textipa{Q}. 
The \ac{BLC}'s transcribers ``restored'' such dropped or deleted sounds and enclosed them in parentheses.
\begin{exe} \label{ex:dropped}
\ex \begin{tabbing}
\hspace{0.6in} \= \hspace{5.5in} \kill
\textsf{*INV:} \> \textsf{li(n)s\a'{o}a\textipa{Q} \, ba\#\, \v{s}en\a'{i} ?}
\end{tabbing}
\end{exe}

\paragraph{Duplications}
Sometimes a word, or, as in (\ref{ex:redundant}), a prefixal clitic, 
is duplicated, and sometimes repeated
several times consecutively. As in (\ref{ex:redundant}), in which the prefixal clitic \textit{we\#} is 
repeated several times, no special annotation is to mark or correct the repetition. Notice that morphological analysis for
for \textit{we\#} is also repeated, so that each \textit{we\#} in the main tier has its ``own'' copy of the morphological analysis.
\begin{exe} \label{ex:redundant}
\ex \textsf{*Classical Hebrew I:\quad we\# we\# we\# we\#\, nigm\textipa{\'a}r } \\
   \textsf{\%mor:\quad conj|we=and\, conj|we=and\, conj|we=and\, conj|we=and} \\
   \textsf{v|nigm\'ar\&root:gmr\&ptn:nifal\&tense:past\&pers:3\&gen:ms\&num:sg=be\_finished }
\end{exe}

%Observations: Note the number (or pound) sign \textsf{\#} at the end of the token \textsf{ba\#}. `in the', which is analyzed in the MA tier as $\texttt{prep|be}$$\sim$$\texttt{det|ha}$. 
%We handle this in different ways in the transcriptions vs. the morphoplogical analyses. Within the 
%morphological analysis tier, the analyses are delimited by spaces, with each single analysis corresponding
%to a word in the transcriptional tier. 
 
\section{Extracting the Input Datasets}\label{sec:extr}
To conduct the experiments, three input wordlists were necessary, 
namely transcriptional list with stress markings (TS), a transcriptional list without stress markings  (TR), and an orthographic list (O):
The words in TS were composed of the \ac{BLC}'s transcriptional symbols, 
whereas those in O
were composed of regular Hebrew letters, following Hebrew spelling conventions. 
In O, the standard Hebrew letters were converted to ASCII characters in a one-to-one
mapping, namely the transliteration mapping of the Hebrew Treebank 
\citep{simaan-et-al:2001}, displayed in table~\ref{tab:ortho-alph}). %adgdhwzxviklmnsypcqret
\begin{table}[ht]
\centering
\caption{Romanization of the Hebrew Alphabet \citep{simaan-et-al:2001}}
\label{tab:ortho-alph}
\setlength{\extrarowheight}{8pt}
\begin{tabular}{c c c c c c c c c c c}
\hline %\hline                      
\begin{cjhebrew}'\end{cjhebrew} & \begin{cjhebrew}b\end{cjhebrew} & \begin{cjhebrew}g\end{cjhebrew} & \begin{cjhebrew}d\end{cjhebrew} 
& \begin{cjhebrew}h\end{cjhebrew} & \begin{cjhebrew}w\end{cjhebrew} & \begin{cjhebrew}z\end{cjhebrew}& \begin{cjhebrew}.h\end{cjhebrew}
& \begin{cjhebrew}.t\end{cjhebrew} & \begin{cjhebrew}y\end{cjhebrew} & \begin{cjhebrew}k|\end{cjhebrew} \\ 
a & b & g & d 
& h & w & z & x & v & i & k \\[12pt]
%& \textsubdot{t} & y & k/\textsubdot{k} & l & m \\[12pt]
 \begin{cjhebrew}l\end{cjhebrew} \begin{cjhebrew}m\end{cjhebrew}
           \begin{cjhebrew}n|\end{cjhebrew} & \begin{cjhebrew}s\end{cjhebrew} & \begin{cjhebrew}`\end{cjhebrew} 
           & \begin{cjhebrew}p|\end{cjhebrew} & \begin{cjhebrew}.s\end{cjhebrew} & \begin{cjhebrew}q\end{cjhebrew} & \begin{cjhebrew}r\end{cjhebrew} & \begin{cjhebrew},s\end{cjhebrew}/\begin{cjhebrew}+s\end{cjhebrew} & \begin{cjhebrew}t\end{cjhebrew} \\
	  l & m & n & s & y & p & c & q & r & e & t \\
\hline
\setlength{\extrarowheight}{8pt}
\end{tabular}
\end{table}
O was obtained by mapping each transcriptional representation 
in TS onto an orthographic representation. For example, \textipa{hitkawanti}$_TS$ $\to$
\textipa{htkwnti}$_O$ and \textipa{katavti}$_TS$ $\to$ \textipa{ktbti}$_O$. The TR words were obtained by replace the accented vowel characters in the TS list with their unaccented counterparts.
Also necessary were two sets of morphological segmentations, namely $\text{T}_{SEG}$ and $\text{O}_{SEG}$, where:
\begin{itemize}
\item $\text{TS}_{SEG}$ = segmentations for 10 percent of the words in TS.
\item $\text{TR}_{SEG}$ = $\text{TS}_{SEG}$, except with the accented vowels replaced
with unaccented vowels.
\item  $\text{O}_{SEG}$ = segmentations for 10 percent of the words in O.
\end{itemize} 
A third set of segmentations TR
Each acted as a gold-standard in the extrinsic 
component of the evaluation phase. (see chapter \ref{ch:eval}).  

\paragraph{Replacement of Anomalous Forms.} 
The input datasets were extracted from the \ac{BLC}. However, as noted above in 
section~\ref{sec:anomolous}, the \ac{BLC} is by no means free of anomalous forms, 
forms that are ungrammatical with respect to the standard form of the language, 
forms that would convey misinformation about the language if taken at face value. 
Such misrepresentative and potentially misleading forms were excluded from the 
extracted input data.  
Wherever a pair of brackets, i.e., \textsf{[: \textit{corrected-text} ]}, was encountered, 
the material within the brackets was extracted in place of the anomalous word (i.e., the 
word to the immediate left of the left bracket (\textsf{[:})). The 

\begin{exe}\label{ex:replace}
	\ex Replacing anomalous forms with their bracket-enclosed corrections
	\begin{xlist}
	   \ex \textsf{*Classical HebrewI:}\quad\textsf{po\, ye\v{s}\, \textbf{patux@c\, [: pat\'{u}ax ]}\, d\'{e}let} $\quad\to\quad$
	   \textsf{po ye\v{s} \textbf{pat\'{u}ax} d\'{e}let}
%	   \textsf{\%mor:}\quad\textsf{adv|po=here exs|ye\v{s}=there\_is} \, \textsf{adj|pat\'uax\&root:ptx\&ptn:qatul\&gen:ms\& \\ num:sg\&src:deverb=open\,  
%	n|d\'elet\&root:dlt\&ptn:qetel\&gen:fm\&num:sg\&stat:unsp} 
	   \ex \textsf{*Classical HebrewI:}\quad\textsf{\textglotstop\'{o}\textsubdot{t}o\, \textbf{micpacef@c}\, \textbf{[: mecafc\'ef ]\, [*]}} $\quad\to\quad$ \textsf{\textglotstop\'o\textsubdot{t}o\, \textbf{mecafc\'ef}}
%\textsf{\%mor:}\quad\textsf{n|\textipa{P\'o\.*t}\&gen:ms\&num:sg\&stat:unsp=car\, cifc\'ef\&root:cpcp\&ptn:piel\&gen:ms\&num:sg=twitter/beep/ignore} 
	\end{xlist}
\end{exe} 

\paragraph{Prefixal clitics.}
Whenever a word in the main tier is preceded by one or more prefixal clitic, we concatenate them one to another and attach the whole sequence to the base word. We discard all `\texttt{\#}' signs.
\begin{exe}\label{ex:preclitics}
	\ex
	\textsf{we\#\, \v{s}e\# me\textipa{Q}arbev\'im} $\quad\to\quad$ \textbf{\textit{\textsf{we\v{s}e}}}\textsf{me\textipa{Q}arbev\'im}\\
	\textsf{conj|we conj:subor|\v{s}e\, part|\textipa{P}irb\'ev\&root:\textipa{Q}rbb\&ptn:piel\&gen:ms\&num:pl} $\quad\to\quad$  \\
	\textit{\textbf{\textsf{conj:we\&conj:subor:sh\&}}}\textsf{part|\textipa{P}irb\'ev\&root:\textipa{Q}rbb\&ptn:piel\&gen:ms\&num:pl}
\end{exe}

\paragraph{Complex adverbs.} In the \ac{BLC}, all adverbs are characterized as atomic, unanalyzable morphological units. That is,
the analysis any adverb, no matter how morphologically complex, is simply ``adv", as in 
examples (\ref{ex:adv:bediyuq}) and (\ref{ex:adv:dscr})  These show the \ac{BLC}'s treatment of the adverbs \textit{\textsf{bediy\'{u}q}} and \textit{\textsf{me\textglotstop{a}xoran\'{i}t}}, respectively. Both are 
morphologically complex.

\begin{exe}
\ex \label{ex:adv:bediyuq}
	\begin{tabbing}
	\hspace{0.6in} \= \hspace{5.5in} \kill
	\textsf{*INV:} \> \textsf{ken ze \textbf{bediy\a'{u}q} xat\a'{u}l .} \\
	\textsf{\%mor:} \> \textsf{co|ken=yes\, pro:dem|ze\&pers:3\&gen:ms\&num:sg=it/this} \\
				\> \textsf{\textbf{adv|bediy\a'{u}q=exactly/precisely}} \\
				\> \textsf{n|xat\a'{u}l\&gen:ms\&num:sg\&stat:unsp=cat .}
	\end{tabbing}
\ex \label{ex:adv:dscr}
	\begin{tabbing}
	\hspace{0.6in} \= \hspace{5.5in} \kill
	\textsf{*INV:} \> \textsf{\textglotstop{i}\_{\textglotstop}{e}f\v{s}\a'{a}r \, raq \, \textbf{me\textglotstop{a}xoran\a'{i}t}\, 
		nto@c\, h@c .} \\
	\textsf{\%mor:} \> \textsf{adv|{\textglotstop}i\_{\textglotstop}ef\v{s}\a'{a}r=impossible \, adv|raq=only}\\
	 \> \textsf{\textbf{adv|me{\textglotstop}axoran\a'{i}t=from\_behind}\, chi|nto\, chi|h .}
	\end{tabbing}
\end{exe}

The adverb \textit{bediy\'uq} `precisely, exactly'
is composed of the prefixal preposition \textit{be-} `in' and the 
noun \textit{diy\'uk} `exactitude, accuracy', which is itself composed of the 
root $\surd$d.y.q and the nominal vowel pattern C\textbf{i}C\textbf{\'u}C 
a pattern that implies a relationship to a verb of the \textit{Piel} binyan.  
The adverb \textit{\textsf{me\textglotstop{a}xoran\a'{i}t}} in 
(\ref{ex:adv:dscr}) is even more complex. It has two nominalizing
derivation affixes \textit{\textsf{-an}} and \textit{\textsf{-it}} in addition 
to the prefixal preposition \textit{\textsf{me/i-}}. Moreover, it contains the 
root $\surd$\textsf{\textipa{P}.x.r}, which is generally associated with meanings 
related to `late' and `after'.

I thus expanded the morphological analyses of complex adverbs in order to capture at 
least some of the derivational morphology of these adverbs.
The (originally) simplistic morphological analyses of complex adverbs were expanded.
But I did not go so far as to delineate morphomes, as this would 
be straying too far from the rest of the analyses in the \ac{BLC}. Such 
analyses would be out of place among all of the other analyses in corpus. 
This would at best be a futile, and at worst, experimentally detrimental.

The expansion of adverb analyses thus consisted of the following limited set of actions. 
\begin{enumerate}
\item If the adverb in question is a noun to which a prefixal preposition is attached, e.g., \textit{be-diy\'uq} (\textit{be} `in' + \textit{diy\'uq} `exactitude' = `exactly'),  %(for such combinations often constitute adverbs),
analyze it as noun bearing a prefixal preposition, not as an adverb. (In general, prefer lower-level, more primitive analyses to higher-level,
more interpretative ones.) 
\item Otherwise: %, identify any prefixal prepositions that contribute to the adverb's form.
    \begin{enumerate}
        \item Identify any prefixal prepositions that contribute to the adverb's form.
        \item Specify the \emph{root}, if any is present.
        \item Specify the \emph{vowel pattern}, if any is present. (Generally, if there is a root, there will be a vowel pattern.) 
    \end{enumerate}
\end{enumerate}

\paragraph{Compound nouns.}
Compound nouns in both Classical Hebrew and Modern Hebrew are made up of a \emph{chain} of 
one or more nouns in the \emph{construct} state followed by a final noun
in the \emph{absolute} state. The former is marked by reduced stress 
and the latter by a normal stress assignment. The following examples 
illustrate the way compound nouns are treated in the \ac{BLC}.
\begin{exe}
\ex \label{ex:cstr:pasey}
	\textsf{pas\'{e}y+ha+rak\textipa{\'{e}}vet} \\
	\textsf{n:det|+n|pas\&gen:ms\&num:pl\&stat:comp-\'{e}y+det|ha+n|rak\textipa{\'{e}}vet}
\ex \label{ex:cstr:shaat} 
	\textsf{\v{s}\textglotstop{at}+sip\'{u}r .} \\
	\textsf{n|+n|\v{s}a\textipa{Q}\'a\&gen:fm\&num:sg\&stat:comp-\'at+n|sip\'ur .}
\ex \label{ex:cstr:bdiqat} 
	\textsf{bdiq\'{a}t+\textipa{P}ozn\'{a}yim} \\ 
	\textsf{n|bdiq\'{a}\&root:tbd\&ptn:tbd\&gen:fm\&num:sg\&stat:bound-\'{a}t}
\end{exe}
In the main tier (i.e., the transcription tier), the components of a compound noun are
delimited by the `+' symbol. 

A compound noun consists of at least two nouns. One of these 
(and only one) is the head of compound, that is to say, that it carries 
the morphosyntactic features of the whole compound. In a Hebrew compound 
noun, the first noun
is always the morphosyntactic head, despite its phonologically 
reduced state.
Thus, in (\ref{ex:cstr:pasey}), \textsf{pas\'{e}y} 'stripes/bands' 
is the head of \textsf{pas\'{e}y+ha+rak\'{e}vet} `the railroad 
tracks.'\footnote{The \textit{ha} at the beginning of  
\textsf{\textit{ha}rak\'{e}vet} is the definite article, a prefixal 
clitic. The definite-article clitic attaches not to the compound's 
morphosyntactic head, but rather to its \emph{phonological} head, 
i.e., the final component noun, which bears the compound's primary stress.}

For our purposes, we extract only the first noun of a compound noun, 
discarding the others. 
There are two reasons for doing so:
The first is word length; 
i.e., compound nouns can, in principle, be indefinitely long and comprise
indefinitely many component nouns.
%\marginpar{What is the longest in the data?} 
Even a compound of two nouns begins to exceed the scope 
of a ULM study. morphological learning. It is challenge enough 
to identify a single 
content stem or a single content root.  in a word. 
The second reason the distribution of features among the 
component nouns: Because the initial noun is head, its 
features are \emph{the same as} the features of the whole compound. 
The means that we only have to extract the morphosyntactic 
features of the initial noun to extract the features of the whole 
compound. In fact, the other nouns in the compound will be 
morphosyntactically empty. They still have morphology, of course, 
but this sort of morphology is not annotated in 
the \ac{BLC}. The \ac{BLC} provides only morphosyntactic 
features, which are the morphosyntactic features of the initial 
noun. There is nothing else to extract where compound nouns 
are concerned.

\begin{exe}
\ex \label{ex:cstr:pasey2}
	\textsf{pas\textipa{\'{e}}y+ha+rak\textipa{\'{e}}vet} $\quad\to\quad$ 
	\textbf{\textsf{pas\textipa{\'{e}}y}} \\
	\textsf{n:det|+n|pas\&gen:ms\&num:pl\&stat:comp-\'{e}y+det|ha+n|rak\textipa{\'{e}}vet} $\quad\to\quad$ \\
	\textbf{\textsf{pos:n\&gen:ms\&num:pl\&stat:cstr}}
\ex \label{ex:cstr:shaat2} 
	\textsf{\v{s}\textglotstop{at}+sip\'{u}r} $\quad\to\quad$ \textbf{\textsf{\v{s}\textglotstop{at}}}\\
	\textsf{n|+n|\v{s}a\textipa{Q}\'a\&gen:fm\&num:sg\&stat:comp-\'at+n|sip\'ur} $\quad\to\quad$ \\
	\textbf{\textsf{pos:n\&gen:fm\&num:sg\&stat:cstr}}
\ex \label{ex:cstr:bdiqat2} 
	\textsf{bdiq\'{a}t\, \textipa{P}ozn\'{a}yim} $\quad\to\quad$ \textbf{\textsf{\textsf{bdiq\'{a}t}}} \\ 
	\textsf{n|bdiq\'{a}\&root:tbd\&ptn:tbd\&gen:fm\&num:sg\&stat:bound-\'{a}t} $\quad\to\quad$ \\
	\textbf{\textsf{pos:n\&root:tbd\&ptn:tbd\&gen:fm\&num:sg\&stat:cstr}}
\end{exe}

\paragraph{Other multiword expressions} Sometimes one encounters two or more words joined 
by an underscore character. These are multiword expressions. We exclude them from
the input datasets. 
\begin{exe}
\ex \begin{tabbing}
\hspace{0.6in} \= \hspace{5.5in} \kill
\textsf{\*MOT:}\>\textsf{kol\_ha\_kav\a'{o}d .} \\
\textsf{\%mor:} \> \textsf{co|kol\_ha\_kav\a'{o}d=well\_done}
\end{tabbing}
\end{exe}


\section{Experimental Variables}\label{sec:expvars}
The experimental component of this dissertation consists of two major axes of inquiry. 
One concerns \textsc{representation} of the input data, and the other the \textsc{features}. 
We shall address each of these in turn. 

In chapter~\ref{ch:intro}, we discussed the problem of choosing a feature set. 
We described it as a problem of selecting one finite subset of 
features from an infinite number of possible features.
We shall now revisit this question. Our approach 
will be to think in terms of feature categories, i.e., to define categories of 
features that have favorable properties. We shall also take into account 
the properties of our learning framework, namely the bipartite graph. We shall thus discard feature types 
(or categories) that are at odds with this learning framework. (For example, global features are not well suited to
the nature of the bipartite graph; see section~\ref{sec:features} for an explanation.)
Ultimately, we cannot consider every 
possible feature or feature set. What we can do is produce some 
principled candidate feature sets with which to experiment. 

We shall glean considerable insight from the field of computer vision. 
That is, we shall consider feature 
categories that are significant to computer vision, doing so with an 
eye to adapting them for the purposes of \ac{ULM}. The idea is that 
is actually a very general problem. And thus the same types of features 
sometimes should apply to different types of objects
We shall focus in particular on \emph{invariant} and \emph{variant} 
features. The distinction between these two feature types is highly significant in
computer vision and its various subfields. In the present dissertation, 
we hypothesize that this distinction is also relevant to ULM. 

\subsection {Data Representation} 
\label{sec:datarep}
By \emph{representation} we refer mainly to the alphabet whose 
symbols compose the strings (i.e., words) 
of an input wordlist.
In the present work, three data representations were tested, two transcriptional 
(TS and TR), and one orthographic (O), as described above.
TS is essentially the transcription system of the BLC, and thus TR is the BLC without stress markings. 
Its alphabet is thus the BLC's 34-symbol
transcriptional system, which we discussed above in section.
O consists of TS's words, but mapped onto orthographic 
representations; every character in O is thus
a letter of the 22-letter consonantal Hebrew alphabet.
%T and O differ both qualitatively and quantitatively. 
Arguably, the transcriptional datasets contains more information than O,
since T has a distinct symbol for each of Modern Hebrew's five vowels sounds,
as well as all of the archaic consonantal distinctions found in O. 
%\textsc{data representation} refers to the ``encoding'' of the input
%word lists. Essentially, it refers to a choice between one of two alphabets (and the spelling conventions that 
%accompany each alphabet). The two alphabets are the standard consonantal Hebrew alphabet, consisting of 22 letters,
%and the 34-symbol \ac{BLC} transcriptional system. 
\textsc{data representation} refers to the ``encoding'' of the input
word lists. Essentially, it refers to a choice between one of two alphabets (and the spelling conventions that 
accompany each alphabet). The two alphabets are the standard consonantal Hebrew alphabet, consisting of 22 letters,
and the 34-symbol \ac{BLC} transcriptional system.]

\subsection{Features}   %\label{sec:expvars:features}
\label{sec:features}

\subsubsection{Feature-set Desiderata: Insights from Computer Vision}
\paragraph{Invariance vs. Variance.}
\cite{dudani-et-al:1977} describe three desiderata for features in the 
domain of aircraft identification:
\begin{quote}
\begin{enumerate}
\item The features should be informative. That is, the dimensionality of a 
vector of measurements (feature vector) should be as low as possible, 
consistent with acceptable recognition accuracy.
\item The features should be invariant with translation of the object 
normal to the camera optical axis and with rotation about this axis.
\item The features should either be invariant or depend in a known 
way upon the distance of the object from the camera.
\citep[][p. 40]{dudani-et-al:1977}.
\end{enumerate}
\end{quote}
Though stated in terms of computer vision and image recognition, 
these desiderata (or criteria) are relevant to all varieties of machine 
learning and clustering, including, of course, what Multimorph does, which is to
cluster words according to shared components.  
(see below).

Invariant features are generally considered to be preferable to variant 
features \citep{hossain-et-al:2012}. 
There are different kinds of invariance for different kinds of problems.
\emph{Scale} and \emph{rotation} invariance are just two examples. If a feature 
is scale-invariant, its
value is independent of the size of the object in question. That is, a 
scale-invariant feature
can have the same value for objects $A$ and $B$, regardless of the 
relative sizes of $A$ and $B$. $A$ could be much larger than $B$, for instance, or much smaller,
but in either case, a scale-invariant feature would be oblivious, so to speak, to the difference in size. 
This is important because $A$ and $B$ could in fact be the one and the same object; it might appear 
larger in one photograph simply because 
it was closer to the camera when that photograph was taken.

Sometimes, however, both invariant and variant features are necessary, 
as in optical character recognition \ac{OCR}\citep{trier-et-al:1996}.
%For example, in the field of Optical Character Recognition (\ac{OCR}) 
%provides some good examples of this scenario. 
Rotation-invariant features are considered essential in \ac{OCR} \citep{trier-et-al:1996}, 
at least
insofar as a character's identity is independent 
of its orientation.
And indeed, the identities of most Roman letters, both upper and lower case, are invulnerable to rotation.
For example, if the letter \textsf{A} is rotated 180 degrees, it remains 
recognizable as an \textsf{A}, since its distinguishing features do not change when it is rotated. 

 
However, this is not true of all letters. In many type faces, for instance, 
\textsf{q} can be rotated to become \textsf{b}, and \textsf{u} can be rotated to 
to become \textsf{n}. Often, a rotated (upside-down) \textsf{M} closely 
resembles a \textsf{W}. And should we consider numerals, we would have to deal 
with the famously rotation-variant \textsf{6} and \textsf{9}. If an 
\ac{OCR} system were to rely solely upon rotation-invariant features, it
would not be able to distinguish between, for instance, \textsf{6} and 
\textsf{9}, since the only features that can distinguish \textsf{6} from \textsf{9}
are rotation variant.
% This is not always the case. However, if all the characters are expected to have the same rotation, then rotation-variant features should be used to distinguish between such characters as `6' and `9', and `n' and `u' \citep{trier-et-al:1996}.

\paragraph{Global vs. Local Features.}
Global features describe an image as a whole, whereas local features are concerned
only with a particular region in the image. That is, the value of local feature is dependent
only upon its particular region; it is not affected by other regions. 
In \ac{OCR}, an example of a global feature is \emph{aspect ratio}, defined 
as the width of a character's rectangular bounding box divided by the same 
box's height. Note that aspect ratio is size invariant. Global features 
can be made invariant 
through normalization, and ratios are a means of normalization.

A global feature for ULM could be the number 
of characters in a given word, which could be binned. Another 
could be the consonant to vowel ratio in a word. The question, however, is 
whether such properties are relevant and beneficial to Multimorph's task,
which is to group together words that share components. 
However, global features are not conducive to bipartite graphical learning frameworks.
Recall from chapter~\ref{ch:graph} that an MCMM is a bipartite graph and thus 
satisfies the following:
\begin{enumerate}
\item its nodes are separated into two disjoint sets (or partitions).
\item within each partition, all nodes are independent, i.e., mutually 
nonadjacent.
\end{enumerate}
In an MCMM, the two partitions are the vectors $\textbf{m}_{i}$
and $\textbf{r}_{i}$ (for each word $i$). The former is the vector of 
cluster activities, and the latter
is the \emph{reconstruction} of word $i$'s original 
feature-vector representation of word. (Recall from chapter~\ref{ch:MCMM}, 
specifically section~\ref{sec:architecture}, that $\textbf{r}_i$ is a working
reconstruction of $\textbf{x}_i$, the original and target feature vector for word $i$.)
By the definition of \emph{bipartite}, \emph{every} feature in $\textbf{r}_i$ is independent,
and thus every feature is local. 

Moreover, words tend to be complex objects, often composed of 
multiple morphological units.These morphological units are 
generally to some extent orthogonal. That is, a plural suffix can 
appear with wide variety of stems, for example, and a 
given stem may occur with a wide variety of suffixes.
Two words can share a single morphological component and 
differ in the rest their of their components. Indeed,
they can be more different than they are alike from a cumulative, 
quantitative point of view. Nevertheless,
as far as that one shared component is concerned, these two are 
\emph{the same} and thus co-members of a morphological
class. Global features do not seem well-suited to represent this 
kind of modular similarity. For these reasons, global features were 
not tested in this dissertation. All features were local. 

On the other hand, the invariant vs. variant distinction 
was a focal point in this study.
The kind of invariance at issue was \emph{affixation-invariance}; 
which means that the value of a given feature does not change
when affixes are attached to the beginning or end of the word. 
Two main feature types were tested, namely 
\emph{positional features}, which are affixation-variant, 
and \emph{precedence features}, which are affixation-invariant.

\subsubsection{(In)variant Features for Morphological Learning}
\paragraph{Positional Features.}
Positional features
indicate the presence of a particular
character at a certain position relative to either the beginning or the end of 
a word. For example, \texttt{i@[0]} indicates that \textit{i} is the first 
character, while \texttt{i@[-1]} indicates that \textit{i} is the last character. 
Indices relative to the beginning are non-negative, while those relative 
to the end are negative. In any case, the number of positions considered 
at the beginning is always equal to the number at the end. This number, 
$s$, is an experimental variable.
the variable $s$ is equal to the absolute value of the smallest negative index. 
For example, $s=4$ means that for each character $\alpha$, the following 
features are generated: $\alpha$\texttt{@[0]}, $\alpha$\texttt{@[1]}, 
$\alpha$\texttt{@[2]}, $\alpha$\texttt{@[3]}, $\alpha$\texttt{@[-1]}, $\alpha$\texttt{@[-2]}, 
$\alpha$\texttt{@[-3]}, $\alpha$\texttt{@[-4]}.
That is, we count three positions inward from each word boundary.
Positional features are \emph{variant} 
with respect to affixation, which is to say that positional features are 
defined relative to the absolute beginning 
or end of a given word. 

\paragraph{Precedence Features.}
Precedence features indicate, for any two characters $x$ and $y$,
whether $x$ precedes $y$ within $\delta$ characters,
where $\delta$ is an experimental variable defined as
	\begin{equation}\label{eq:indexdif}
	\delta = \text{index}(x) - \text{index}(y)
	\end{equation}
Note that if $\delta = 1$, the precedence features are 
pairs of adjacent characters, i.e., bigrams.
Precedence features are affixation-invariant. 
Consider for example the word \textsf{bediy\'uq}. 
If $\delta = 1$, \dots 
As an example, consider again the word 
\textsf{we\v{s}eme\textipa{Q}arbevim} `and which confuse', 
whose \ac{BLC} morphological 
analysis appears above in example (\ref{ex:preclitics}). 
This word has two prefixal clitics, namely \textsf{we} 
(`and') and \textsf{\v{s}e} (`which'). %, and one inflectional prefix, namely \textsf{-im} `masc. pl.' 
Consider the features \textsf{b < v}, \, \textsf{e < v}, \,\textsf{\textipa{Q} < r},\, and \textsf{\textipa{Q} < b}. If $\delta=2$, these features would get the 
following values: 
\begin{exe}	
	\ex \textsf{b < v} $ =1 $, \qquad \textsf{e < v} $ =1 $, \qquad\textsf{\textipa{Q} < r} $ =1$, \qquad \textsf{\textipa{Q}< b} $=0$
\end{exe}

All evaluate to 1 or \textsc{true} except \textsf{\textipa{Q} < b}, since
\begin{exe}
	\ex $\text{index}($\textsf{b}$) - \text{index}($\textsf{\textrevglotstop}$) = 9 - 6 = 3$
\end{exe}
which is greater than 2.
The others evaluate to 1 because the difference between indices in their cases is \emph{at most} 2. That is,
\begin{exe}
    \ex \begin{xlist}
	\ex $\text{index}($\textsf{v}$) - \text{index}($\textsf{b}$) = 11 - 9 = 2$ 
	\ex $\text{index}($\textsf{v}$) - \text{index}($\textsf{e}$) = 11 - 10 = 1$ 
	\ex $\text{index}($\textsf{r}$) - \text{index}($\textsf{\textrevglotstop}$) = 8 - 6 = 2 $
    \end{xlist}
\end{exe}
%\begin{exe}\label{ex:preclitics2}
%	\ex
%	\textsf{we\#\, \v{s}e\#\, me\textipa{Q}arbev\'im}\, \textsf{me\textipa{Q}arbev\'im}\\
%	\textsf{conj|we\, conj:subor|\v{s}e\, part|\textipa{P}irb\'ev\&root:\textipa{Q}rbb\&ptn:piel\&gen:ms\&num:pl} 
%\end{exe}

%Now, notice what happens when we remove the prefixal clitics \textsf{we} 
%and \textsf{\v{s}e}, leaving just the present tense, masc. pl. 
%verb \textsf{me\textipa{Q}arbevim}.
%\begin{align*}
%	\text{index}(\textsf{\textipa{v}}) - \text{index}(\textsf{b}) &= 7 - 5 = 2 \quad\to\quad \textsf{b\<v}=1 \\
%	\text{index}(\textsf{\textipa{v}}) - \text{index}(\textsf{e}) &= 7 - 6 = 1 \quad\to\quad \textsf{e\<v}=1 \\
%	\text{index}(\textsf{\textipa{r}}) - \text{index}(\textsf{Q}) &= 4 - 2 = 2 \quad\to\quad \textsf{\textipa{Q}\<r}=1  \\
%	\text{index}(\textsf{\textipa{b}}) - \text{index}(\textsf{Q}) &= 5 - 2 = 3 \quad\to\quad \textsf{\textipa{Q}\<b}=0\\ 
%\end{align*}
\begin{exe}
    \ex \begin{xlist}
	\ex $\text{index}($\textsf{v}$) - \text{index}($\textsf{b}$) = 7 - 5 = 2 \quad\to\quad $ \textsf{b < v} $ =1 $
	\ex $\text{index}($\textsf{v}$) - \text{index}($\textsf{e}$) = 7 - 6 = 1 \quad\to\quad $ \textsf{e < v} $ =1 $
	\ex $\text{index}($\textsf{r}$) - \text{index}($\textsf{\textrevglotstop}$) = 4 - 2 = 2 \quad\to\quad $\textsf{\textipa{Q} < r} $ =1 $
	\ex $\text{index}($\textsf{b}$) - \text{index}($\textsf{\textrevglotstop}$) = 5 - 2 = 3 \quad\to\quad $ \textsf{\textipa{Q} < b} $ =0 $ 
    \end{xlist}
\end{exe}


The feature valuations do not change.
Precedence features are thus invariant with respect to affixation; that is to say, 
they are \emph{affixation-invariant}.
Precedence features are not bound to absolute character positions, i.e., 
absolute indices. They are not defined relative to fixed points such as 
the beginning or end of a word.
%On the other hand, positional features are \emph{variant} 
%with (respect to) affixation, which is to say that positional features are 
%defined relative to the (absolute) beginning 
%or end of a given word. 
%\section{Evaluation paradigms}
%\subsubsection{Intrinsic evaluation}
%\subsubsection{Extrinsic evaluation}

\section{Experimental Program}
The experiments tested different combinations of $s$ and $\delta$ values, 
in particular for
$s = \{0,2,4,6\}$ and $\delta = \{1,2,3\}$. Twelve features sets were derived from combining these $s$ and $\delta$ values:
$\langle s = 0, \delta =1 \rangle$,  $\langle s = 0, \delta = 2 \rangle$, and so on. %, as illustrated in table~(REF),
Each $\angle s, \delta \rangle$ pair corresponds to a distinct feature set that was tested in a particular experiment. 
%In addition, by setting either $s = 0$ or $\delta=0$\footnote{That is, the valuation $\delta = 0$ 
%is actually undefined; $\delta = 1$ corresponds to bigrams, 
%i.e., adjacent characters, so $\delta = 0$ would 
%mean that two characters had the \emph{same} index, which 
%would not make sense. We therefore use $\delta = 0$ as shorthand 
%for ``no precedence features."}
%(but not both equal to zero at the same time), one obtains feature sets comprising either \emph{only} positional features (in which case $\delta = 0$) on \emph{only} precedence features (in which case $s = 0$). 
%Of course, if both $s = 0$ and $\delta=0$ simultaneously, there world be no features at all.
%that contain only one type of feature;
%i.e., if $s=0$, there can be no positional features, and similarly, 
%there can be only one positional features 
%if $\delta=0$.
%Thus, six additional features sets were added to the experimental feature-set lineup: 
%%three additional feature sets were added to the experimental 
%%lineup: 
%three containing only 
%precedence features (i.e., at $\delta =$ 1, 2, and 3), and
%three containing only position features (at $s =$ 2, 4, and 6).

Each of combinations of the $s$ and $\delta$ was combined with each the input-data representations. That is, Multimorph was run on each dataset at each of the feature-parameter combinations.  representations of the input data. Two of these representations were quasi-phonemic transcriptions---one with stress marking and one with out. We shall abbreviate these two as TS and TR, respectively. The third kind of input-data representation was not transcriptional, but rather orthographic (O). 

%The input words were the combination of $s$ and $\delta$, first with the transcriptional datasets (TS and TR) serving as input.  
%The best valuations for $s$ and $\delta$ on T
%were then mapped onto analogous valuations for the O 
%dataset. Because O mostly lacks vowels, many consonant-vowel 
%sequences in T will correspond to a single consonant in 
%O. Thus, we can in many cases estimate $s$ and $\delta$ 
%for O by taking the $s$ and $\delta$ values associated with T and dividing them each by two. %by halving $s_{T}$ and $\delta_{T}$.
%For example, a valuation of 
%$\langle s_T = 6, \delta_T = 2 \rangle$ 
%(i.e. $s$ and $\delta$ with T as input)  would correspond 
%approximately to $\langle s_O = 3, \delta_O = 1 \rangle$.

\section{Summary}

This study involves three main experimental variables. Two are the feature parameters affix length$s$ and precedence span $\delta$. The third variable is the representation of the input data. Three data sets were used in the experiments. Two were transcriptional---one with stress marking and one with no stress marking, and the other was orthographic. The latter two types were derived from the transcriptional data with stress marking. 

%are feathrenput datasets (i.e., wordlists) were compiled: a 
%transcriptional wordlist (T) and an orthographic wordlist (O).
% First, the transcribed words were extracted from the \ac{BLC}, along with along with their \ac{BLC} morphological analyses. Thus T was obtained.
%The words in T were then converted to orthographic representations
%according to the spelling rules of the Hebrew Language 
%Academy. Thus O was derived from T. 

Two feature types were chosen for experimentation, namely \emph{positional features} and \emph{precedence features},
These were chosen because the former is variant and the latter invariant with respect to affixation. That is, e.g., if a prefix within a given word is represented with positional features, its feature-value representation will change of another prefix is attached before it. Thus, the same prefix may have different feature-value representations in different words. Precedence features, on the other hand, are defined in such a way that they are unaffected when additional material is attached to the front or end of words. However, this does not mean that precedence features are going to be better than positional features in every case. Some morphological units, like the characters may require positional features, just as the characters 6 and 9 require position-variant features in \ac{OCR}. 

%ary depending on whether an affix is attached eature s attached to the would with different \emph{positional features} if an affix is \emph{variant} and \emph{invariant}, respectively, with respect to affixation.
%\item 
The focus of the next chapter will be the methods whereby the results of the experiments were evaluated. We shall see why, for instance, we needed to extract not just the words from the \ac{BLC}, but their morphological analyses. 

