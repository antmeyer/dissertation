\chapter{Multimorph}
\label{ch:experi}
\section{Introduction}\label{sec:experi-intro}
%This chapter will describe the experimental setup,
This chapter will be concerned with the unsupervised morphological learning system Multimorph. Chapter~\ref{ch:MCMM} described the Multiple Cause Mixture Model (MCMM), a general unsupervised learning model (or algorithm). An MCMM serves as the core learning algorithm of Multimorph. The present chapter
% describes a particular morphological learning system that uses an MCMM as its core learning algorithm MCthe 
 describes the steps necessary to transform an MCMM into Multimorph,
% up into Mu   fully realized morphological learning system 
%chapter~\ref{ch:MCMM}. 
to bridge the gap between the general core and the fully realized system. 
% a particular unsupervised morphological learning system. 
For instance, one crucial matter discussed in this chapter is the question of \emph{features}, the elemental data descriptors that shape Multimorph's view of its input data and provide a common framework for establishing relations between data points. %(through its MCMM) relates one data point to another. 
Also in this chapter, we describe the preparation of Multimorph's input data an the key experimental variables that factored into Multimorph's evaluation.
%that is, the steps I took to prepare for and run the experiments. 

This chapter's discussion
is divided into two main sections: The first, section~\ref{sec:datasource}, concerns the extraction of the input data, including a description of the original data source. The second, section~\ref{sec:expvars}, discusses the experimental variables. The experimental variables comprise two broad categories: 
\begin{enumerate}
\item The representation of the input data. (For instance, the input words could be represented orthographically, according to the spelling conventions of Modern Hebrew, or they could be transcribed in some way.) The three choices for data representation are described in section~\ref{sec:datarep}.
%(i.e., orthographic vs. transcriptional) 
\item The precise definitions of the feature types, which varied according to the values of certain feature parameters. These parameters are discussed in section~\ref{sec:features}.
\end{enumerate}  

Multimorph can take as input \emph{any} list of words. The words can be of any
language, although Multimorph does expect the input strings to be composed
of alphabetic symbols. It also assumes that each symbol will be atomic rather
than composite. 
For example the symbol \textsf{\textipa{\.*k}} can be represented in Unicode either 
as a sequence of two code points, namely \texttt{U+006B, U+0323} 
(where \texttt{U+0323}
corresponds to the dot), or as the \emph{single} code point \texttt{U+1E33}. 
In its present form, Multimorph 
expects the latter. I mention this because the data source 
expresses
such characters in the former way, i.e., as sequences of code points. I thus had
to map the sequences onto atomic code points such as \texttt{U+0323} 
for \textsf{\textipa{\.*k}}.

When Multimorph reads the input wordlist, 
it maps each word onto
a sequence of 1s and 0s called a \emph{feature vector}, 
where each 1 or 0 is the value of a
particular feature. 
Features often follow some sort of template such as $\alpha$@[x], i.e., `character $\alpha$ occurs at position $x$' where $x$ is a member of an appropriate range of integers. This feature template can instantiated as many different specific features, and thus it constitutes a feature family (or category, type, etc.). The question of which feature types (as well as which particular feature instantiations) are most effective is one of this dissertation's research questions. 

\section{Data Source: The Berman Longitudinal Corpus}
\label{sec:datasource}
\subsection{Corpus Overview}
\label{sec:corpus-overview}
The input datasets (i.e., wordlists) were extracted 
from the BLC, \citep{berman-weissenborn:1991}. 
The BLC is part of the Hebrew section of the 
CHILDES Corpus \citep{macwhinney:2000a}, a corpus 
of transcribed conversations between young children 
and adults. I chose the BLC because 
it is one of the few sources of \emph{transcribed} Modern Hebrew. 
Most other Hebrew sources consist of printed material, 
such as newspaper text, and thus is orthographic 
rather than transcribed. The Hebrew alphabet has no 
dedicated letters for vowels, and thus Hebrew 
orthography is largely without vowels. I wanted data in which the vowels were 
fully represented. Another advantage of the BLC is that 
it is quite extensive. It contains 110,819 utterances, which, in turn, comprise 417,938 word tokens (13,828 word types) \citep{albert-et-al:2012}.
I am unaware of a larger source of 
transcribed Modern Hebrew. 

Each file in the BLC is the transcription of a 
particular session. The participants, who are identified 
in each file's header, can include, for example, the parents,
 other relatives, such as a grandmother, 
the researcher (or \emph{investigator}) conducting the 
session, and the child him or herself, 
who is called the \emph{target child}. All participants 
were native speakers of Modern Hebrew. The BLC comprises 
the transcriptions of many individual recording sessions. 
Each child's sessions were conducted over a period of 
12 to 19 months. Each child was between 16 and 21 months 
old when his/her recording sessions began, and between 
28 to 39 months old ($2\frac{1}{3}$ to $3\frac{1}{4}$ 
years old) when they ended.

\begin{figure}[t]
\begin{mdframed}
\begin{tabbing}
\hspace{0.6in} \= \hspace{0.6in} \=  \hspace{0.5in} \= \hspace{0.6in} \= \hspace{3.4in} \kill
\textsf{*MOT:} \> \textsf{ma} \> \textsf{\textipa{P}\a'{i}ma\textipa{P}} \> \textsf{\textipa{P}o\textipa{\.*s}\a'{a}} \>  \textsf{ba\# mi\textipa{\.*t}b\a'{a}x ?} \\
\> \textit{What [is]} \> \textit{Mom} \> \textit{doing} \> \textit{in.\textsc{def}+kitchen ?} \\[6pt]
\textsf{\%mor:} \> \textsf{que|ma=what n|\textipa{P}\a'{i}ma\textipa{P}\&gen:fm\&num:sg\&stat:free=mother} \\
 \> \textsf{part|\textipa{P}a\textipa{\.*s}\a'{a}\&root:\textipa{P}\textipa{\.*s}y\&ptn:qal\&gen:fm\&num:sg-\a'{a}=do} \\
   \> \textsf{prep|be~det|ha n|mi\textipa{\.*t}b\a'{a}x\&gen:ms\&num:sg\&stat:unsp=kitchen ?}\\[6pt]
\textsf{\%gra:} \>	\textsf{1|3|ANONAGR 2|3|AAGR 3|0|ROOT 4|3|MPRE 5|6|MDET 6|4|APREP 7|3|PUNCT}\\[6pt]
\textsf{CHI:} \> \textsf{rox\a'{e}cet} \> \textsf{kel\a'{i}m .}\\
		\> \textit{Washing} \> \textit{dishes .}  \\[6pt]
\textsf{\%mor:} \> \textsf{part|rax\a'{a}c\&root:rxc\&ptn:qal\&gen:fm\&num:sg-et=wash} \\
    \>  \textsf{n|kli}\&\textsf{gen:ms\&num:pl\&pl:masc:match\&stat:free-\a'{i}m=tool .} \\[6pt]
\textsf{\%gra:} \> \textsf{1|0|ROOT 2|1|ANONAGR 3|1|PUNCT}
\end{tabbing}
\caption{Excerpt from the Berman Longitudinal Corpus (BLC)}
\label{fig:excerpt}
\end{mdframed}
\end{figure}
Figure~\ref{fig:excerpt} shows an excerpt from the BLC. 
This excerpt contains two utterances, one spoken by the 
target child (CHI), and the other by the child's mother (MOT).
The first utterance in figure~\ref{fig:excerpt} is that of mother,
who says, ``What is Mom doing in the kitchen?'' The child
then replies \textsf{[rox\a'{e}cet kel\a'{i}m]}, `Washing dishes.'\footnote{The BLC's gloss `tools' is a generic translation of the Hebrew \textit{kel\'{i}m}. However, the context here suggests `dishes'
as a better translation.}
I have inserted these English words as glosses in italics as additional 
rows of text beneath the rows of transcribed words in figure~\ref{fig:excerpt}. 
Note these two extra rows do not appear. 
in the actual BLC.

The asterisk (*) preceding the labels CHI and \textsf{MOT} 
indicates that these tiers are \emph{main} tiers, i.e.,  
utterance tiers. Each utterance is accompanied by two 
additional tiers, 
namely, a morphological tier, labeled \textsf{\%mor}, 
and a syntactic (or grammatical) tier, labeled \textsf{\%gra}. 
The syntactic tier is not relevant to the present thesis,
so we shall not refer to it further. The morphological tier 
has a hierarchical structure. At the highest level, it consists of a 
series of space-delimited morphological analyses, 
There is exactly one analysis for each word in the main tier.  
Each \emph{individual} morphological analysis consists
of \textit{morphosyntactic properties}. These are delimited by the 
ampersand symbol (\textsf{\&}). Morphosyntactic properties are 
generally expressed as feature-value pairs of the 
form \textsf{\textit{feature}:\textit{value}}, e.g., 
\textsf{gen:fm} (`gender: feminine'). 

In the remainder of this section, we shall first discuss the 
BLC's unique transcription system, a system that 
honors Hebrew orthography as much as it does its spoken 
pronunciation. We shall then discuss some key aspects of 
the BLC's morphological annotation scheme. The 
transcription system is important for the present study 
because the features
depend on the alphabet in which the data is represented.
 The morphological annotation 
is significant because  the BLC's morphological annotations must 
serve as raw material for creation of  the intrinsic evaluation's 
gold-standard categories (see chapter~\ref{ch:eval}). 

\subsection{Transcription System}
\label{sec:transcription}

\begin{table}[t]
\centering
%\caption{Transcription System of the Berman Longitudinal Corpus}
%\label{tab:blc-alphabet}
\subtable[Consonants\label{subtab:trans-cons}]{
\setlength{\extrarowheight}{8pt}
\begin{tabular}{c c c c c c c c c c c c c}
\toprule                     
\begin{cjhebrew}'\end{cjhebrew} & \begin{cjhebrew}b\end{cjhebrew} & \begin{cjhebrew}g\end{cjhebrew} & \begin{cjhebrew}d\end{cjhebrew} 
& \begin{cjhebrew}h\end{cjhebrew} & \begin{cjhebrew}w\end{cjhebrew} & \begin{cjhebrew}z\end{cjhebrew}& \begin{cjhebrew}.h\end{cjhebrew}
& \begin{cjhebrew}.t\end{cjhebrew} & \begin{cjhebrew}y\end{cjhebrew} & \begin{cjhebrew}k|\end{cjhebrew} & \begin{cjhebrew}l\end{cjhebrew} 
&\begin{cjhebrew}m|\end{cjhebrew}\\ 
\textipa{P} & b/v & g & d 
& h & w & z & x 
& \textsubdot{t} & y & k/\textsubdot{k} & l & m \\[12pt]
           \begin{cjhebrew}n|\end{cjhebrew} & \begin{cjhebrew}s\end{cjhebrew} & \begin{cjhebrew}`\end{cjhebrew} 
           & \begin{cjhebrew}p|\end{cjhebrew} & \begin{cjhebrew}.s\end{cjhebrew} & \begin{cjhebrew}q\end{cjhebrew} & \begin{cjhebrew}r\end{cjhebrew} 
           & \begin{cjhebrew},s\end{cjhebrew}/\begin{cjhebrew}+s\end{cjhebrew}
           & \begin{cjhebrew}t\end{cjhebrew} & & \begin{cjhebrew}z\end{cjhebrew}$^\prime$ & \begin{cjhebrew}g\end{cjhebrew}$^\prime$ & \begin{cjhebrew}.s|\end{cjhebrew}$^\prime$ \\
	  n & s & \textipa{Q} 
	  & p/f & c & q & r & \v{s}/\textsubdot{s} 
	  & t & &  \v{z} & \textipa{J} & \c{c} \\
\bottomrule
\end{tabular}
}
\subtable[Vowels\label{subtab:trans-vowels}]{
\setlength{\extrarowheight}{8pt}
\begin{tabular}{c c c c c}
%\hline
\toprule
a & e & i & o & u \\
\'a & \'e & \'i & \'o & \'u \\
%\hline
\bottomrule
\end{tabular}
}
\caption{Transcription System of the Berman Longitudinal Corpus}
\label{tab:blc-alphabet}
\vspace{6pt}
\end{table}

The BLC's transcription system, summarized in table~\ref{tab:blc-alphabet}, %~\ref{subtab:trans-vowels} and \ref{subtab:trans-cons}, 
eludes simple one-word 
characterizations such as ``orthographic,''
``phonetic,'' or ``phonemic.'' It is in fact a hybrid system, drawing
both from phonetics and orthography \citep{albert-et-al:2013}. 
It is a transcription system in some ways and a transliteration 
system in others. It is a transcription system in that it has 
five dedicated vowel symbols, 
namely \{a, e, i, o, u\}, each of which matches one of the 
vowels in Modern Hebrew's five-vowel inventory. 
At the same time, however, 
it is a \emph{transliteration} system in that it is sensitive to 
orthographic distinctions that Modern Hebrew does not have.
The present consonantal alphabet of Hebrew originated in the 
language's classical period, with each 
consonantal grapheme corresponding to 
a distinct consonantal phoneme in Classical Hebrew \citep{rendsburg:1997}. The alphabet itself
has remained largely unchanged 
into the present day \citep{weinberg:1975, ravid:2005}; i.e. it has the same letters as it 
did in antiquity. The phonemic inventory 
of Hebrew, however, has changed. Thus, the correspondence 
between the graphemes of the Hebrew
alphabet and the phonemes of Modern Hebrew is far from perfect. 
The consonant inventory of Modern Hebrew
has undergone a number of neutralizations, leaving 
Modern Hebrew with a smaller inventory of consonant phonemes than
Classical Hebrew had. %Hebrew had in the Biblical period (i.e., the older part  
The mapping 
from consonantal graphemes in the Hebrew alphabet
to Modern Hebrew consonantal phonemes is therefore many-to-one.

\begin{table}[t]
\centering
\setlength{\extrarowheight}{8pt}
\begin{tabular}{l l c c c}
\toprule
 & Classical Hebrew  & Modern Hebrew   &  BLC  & Gloss \\
\midrule
a. & \textipa{kot\'eB}  & \textipa{kot\'ev} & \textipa{kot\'ev} & `writes, writing' \\
b. & \textipa{bor\'e\textbf{a}\textcrh} & \textipa{bor\'e\textbf{a}x} & \textipa{bor\'e\textbf{a}x} & `escapes, escaping'  \\
c. & \textipa{yod\'e\textbf{a}Q} & \textipa{yod\'e\textbf{a}} & \textipa{yod\'e\textbf{a}Q} & `knows, knowing' \\\bottomrule
\end{tabular}
\caption{\emph{a}-insertion before historical pharyngeals}
\label{tab:a-insertion}
%\vspace{3pt}
\end{table}

In its rendering of consonants, the BLC's transcriptional system 
favors orthography over actual pronunciation \citep{albert-et-al:2013}.
It honors a number of historical distinctions that have been preserved in the orthography, 
i.e., the alphabet and 
spelling conventions, but neutralized or otherwise lost in spoken Modern Hebrew. 
Table~\ref{tab:phon-neut} compares 
(reconstructed) Classical Hebrew phonemes, which are taken to be in a one-to-one 
correspondence with the letters of 
the Hebrew alphabet, Modern Hebrew speech sounds, and transcription symbols 
from the BLC. Notice that the
the Modern Hebrew column has the fewest distinctions.

\begin{table}[ht]
\centering 
\setlength{\extrarowheight}{8pt}
\begin{tabular}{l c c c}
\toprule
IPA & Orthography & BLC & Gloss  \\
\hline
    \textipa{[yad\'{a}]} &  \begin{cjhebrew}`dy\end{cjhebrew}  & \textipa{yad\'{a}Q} & `(he) knew' \\
    \textipa{[yad\'{a}]} &  \begin{cjhebrew}hdy\end{cjhebrew}  & \textipa{yad\'{a}h} &  `her hand' \\
\bottomrule
\end{tabular}
\caption{Ambiguity arising from the loss of consonantal distinctions.}
\label{tab:yada} 
\end{table}

The orthography of Modern Hebrew thus preserves the shadows of 
lost Classical Hebrew phonemes, as it were. 
Similarly, many morphophonological processes in Modern Hebrew
preserve residues of Classical Hebrew phonotactics and phonological processes. 
That is, even though the triggering contexts of these Classical Hebrew processes 
have been obscured or altogether lost due to sound changes, 
many have nonetheless been revived as fully-fledged components of Modern Hebrew. 
For example, in Classical Hebrew, the consonants \begin{cjhebrew}.h\end{cjhebrew} 
(\textit{\textipa{\textcrh{et}}}) and \begin{cjhebrew}`\end{cjhebrew}
(\textit{`ayin}) were both pharyngeal consonants; the former 
was a voiceless fricative (IPA \textipa{[\textcrh]}), and the latter a 
voiced stop (IPA \textipa{[Q]}). There was a process in Classical Hebrew 
whereby the [+low] vowel \textipa{[a]} was inserted between 
a [-low] vowel and a pharyngeal consonant to
mediate the transition between the [-low] vowel and the 
[+low] pharyngeal. This process is illustrated in table~\ref{tab:a-insertion}. 

Modern Hebrew, however, has no pharyngeals, having 
inherited its consonantal inventory 
largely from central and eastern European languages 
\citep{montoya:2014}. 
In Modern Hebrew, \textipa{[\textcrh]} 
is pronounced as a voiceless velar fricative 
(IPA \textipa{[x]}), and \textit{`ayin} 
is usually not pronounced at all. It has become 
phonologically 
equivalent to the historical glottal stop 
\begin{cjhebrew}'\end{cjhebrew} 
(\textit{'alef}). Both \begin{cjhebrew}'\end{cjhebrew} and 
\begin{cjhebrew}`\end{cjhebrew} 
are sometimes realized as glottal stops, but are 
often not pronounced at all, 
especially in fast speech \citep{matras-and-schiff:2005,berman:1985}. 
Nevertheless, Modern Hebrew has maintained the pre-pharyngeal 
\textit{a}-insertion process, as though the graphemes 
\begin{cjhebrew}`\end{cjhebrew} (\textit{`ayin}) and 
\textit{\textipa{\textcrh{et}}} still corresponded 
to phonological pharyngeals. This is shown in table~\ref{tab:a-insertion}:
In row (c), column Modern Hebrew, the \textit{a} is inserted 
even though the historical *\textipa{\textrevglotstop} 
(\textit{`ayin}) sound has vanished. In fact, no sound remains in this 
word-final position, not even a glottal stop for most 
speakers. The inserted \textit{a} thus ends up being the 
word's final phonological segment. And yet it is not the final segment
in the BLC's transcription, namely \textipa{yod\'eaQ} in row (c). 
The BLC includes the grapheme \begin{cjhebrew}`\end{cjhebrew} 
(\textit{`ayin}) in the form of the transcriptional 
symbol \textipa{[\textrevglotstop]}, as though it
were an actual speech sound.

Such a hybrid system offers both advantages and disadvantages to a 
ULM system like Multimorph. 
On the one hand, the inclusion of such lost consonants as 
\begin{cjhebrew}`\end{cjhebrew} 
(\textit{`ayin}) provides a system with additional and potentially 
quite valuable information. 
Phonemic mergers can obscure category memberships and thus 
create ambiguity. For instance, 
the forms for `(he) knew' and `her hand' in  table~\ref{tab:yada}
have identical pronunciations in Modern Hebrew, as indicated 
by their identical transcriptions in the International Phonetic Alphabet (IPA)
in \ref{tab:yada}. And yet they are different. 
The former is a 3rd-masculine-singular past-tense verb of the 
\emph{qal} binyan. Its root consists of the \emph{three}
consonants \textit{\textipa{y.d.Q}}, which one must 
know in order 
to connect this verb to derivationally related words. 
The second \textipa{[yad\`{a}]} 
in table~\ref{tab:yada} is the noun \textit{yad} plus 
the 3fs possessive suffix 
\textit{-a(h)}, the final \emph{h} of which is not articulated. 
Because the BLC's transcriptional system preserves 
certain consonants and 
inter-consonant distinctions, it preserves information and 
thus reduces ambiguity. 
This is probably going to be advantageous to a ULM 
system, even if the preserved 
information is not entirely accurate vis-\`{a}-vis Modern Hebrew 
pronunciation.

On the other hand, the inclusion of these non-Modern 
sounds means that more features are necessary to describe 
words. The larger number of features results in longer processing times. 
A larger number of features can also decrease accuracy 
if the additional features are not useful. 
In addition, increasing the number of symbols does not 
always help to clarify true relationships; sometimes it 
obscures them. For example, the BLC's transcriptions 
represent the spirantization of the certain oral obstruents; 
in particular, \textipa{/b/} $\to$ v, \textipa{/p/} $\to$ f, and \textipa{/k/} $\to$ \textsubdot{k} 
in the context
Vowel \_\_. Hence, the underlying \textipa{/b/} in the root \textit{k.t.b} 
(`\textsc{write}') often manifests as [v], as it does in \textit{katavti}
(`I wrote') and 
\textipa{\textit{yi{\.*k}t\'ov}} (`he will write'). The latter exhibits not only
the alternation 
\textipa{/b/}~$\to$~v, but also \textipa{/k/}~$\to$~\textsubdot{k}.
%two altered characters. 
Recall, however, from section~\ref{sec:experi-intro}, that even \textit{\textipa{\.*k}} looks like \textit{k} with a dot below it,
Multimorph would have seen them as entirely distinct symbols, just as \textit{\textipa{b}} and \textit{v} are distinct symbols.
In Multimorph's input data, \textit{\textipa{\.*k}} and \textit{\textsubdot{k}} were each represented as a  distinct atomic unicode character.
%Multimorph thus did not not see \textit{\textipa{\.*k}} and \textit{\textsubdot{k}} as fundamentally related. 
All unicode characters were atomic and monolithic. Symbols with dots (e.g., \textsubdot{k}) or accent marks (e.g., \'{u}) were represented as \textit{precomposed} unicode characters and thus were in effect as atomic as any other character.
%and \textit{k} as 
%entirely different symbols, not as allophones
%of the same phoneme. The same would be true for \textit{b} 
%and \textit{v}.  

%\begin{cjhebrew}yd`\end{cjhebrew}
%For the purposes of learning Hebrew morphology, this is probably useful information. 
%The more information the better, Dawg.
%For example, the presence of the phantom \textipa{Q} 
%probably makes it easier to identify the root 
%$\surd$y-d-\textipa{Q}

The grapheme \begin{cjhebrew}`\end{cjhebrew} (\textit{`ayin}) is not the only 
grapheme to have 
lost its ancient phonemic affiliation. 
The graphemes \begin{cjhebrew}.t\end{cjhebrew} 
(\textit{\textipa{\.*te\.*t}}), \begin{cjhebrew}s\end{cjhebrew} 
(\textit{\textipa{same\.*k}}), correspond to emphatic, i.e., 
pharyngealized, consonants in Classical 
Hebrew, probably pharyngealized versions of [s] of [t] \citep{matras-and-schiff:2005}.
Modern Hebrew, however, lacks pharyngealized consonants just as 
it lacks pharyngeals. 
The consonant \begin{cjhebrew}q\end{cjhebrew} (\textit{qof}, 
IPA \textipa{[q]}) was uvular and 
possibly pharyngealized in Classical Hebrew, but in Modern Hebrew, 
it has merged with the velar voiceless stop
\begin{cjhebrew}k|\end{cjhebrew} (\textit{kaf}, IPA \textipa{[k]}).
%Thus, 
%as the \emph{emphatic consonants}, were once associated with pharyngealized phonemes, but now they are pronounced simply as [s] and [t]. 
Similarly, the pronunciations 
%(or affiliated phonemes) 
of  \textit{\textipa{same\.*k}} and \textit{\textipa{\.*te\.*t}} 
have merged with those of \textit{sin} and \textit{tav} respectively, 
 so that \textit{\textipa{same\.*k}} and \textit{\textipa{sin}} 
 are both pronounced as [s], and \textit{\textipa{\.*te\.*t}} and 
 \textit{tav} as [t]. But whereas the phonemic inventory of 
 Modern Hebrew has lost distinctions, the Hebrew writing system has preserved several inter-consonantal distinctions.

\begin{table}[t]
\centering 
\setlength{\extrarowheight}{9pt}
\begin{tabular}{l c c c c }
\toprule
\multirow{2}{*}{Heb. Letter} & Special &  \multicolumn{2}{c}{IPA} & \multirow{2}{*}{BLC}\\\cline{3-4}
    & Context & BH  & Modern Hebrew & \\
\midrule
\begin{cjhebrew}'\end{cjhebrew} ('alef) & &  \textipa{P} & -- & \textit{\textsf{\textipa{P}}} \\
\begin{cjhebrew}`\end{cjhebrew} (`ayin) & &\textipa{Q} & -- & \textit{\textsf{\textipa{Q}}} \\
\begin{cjhebrew}q\end{cjhebrew} (qof )& & \textipa{q} & \textsf{\textipa{k}} & 
\textit{\textsf{\textipa{q}}} \\
\multirow{2}{*}{\begin{cjhebrew}k|\end{cjhebrew} (kaf)} & & \textipa{k} & \textsf{\textipa{k}} & \textit{\textsf{\textipa{k}}} \\
		         & {Vowel\,\_} & \textipa{x} &\textsf{\textipa{x}} & \textit{\textsf{\textipa{\.*k}}} \\
 \begin{cjhebrew}x\end{cjhebrew} (\textipa{\textsubdot{h}et}) & &\textipa{\textcrh} & \textsf{\textipa{x}} & \textit{\textsf{\textipa{x}}} \\
 \begin{cjhebrew}s\end{cjhebrew} (\textipa{same\.*k}) & & \textipa{\textsuperimposetilde{s}} & \textsf{\textipa{s}} & \textit{\textsf{\textipa{s}}} \\
  \begin{cjhebrew},s\end{cjhebrew} (\textipa{sin}) & & \textipa{\textbeltl}  &  \textsf{\textipa{s}} & \textit{\textsf{\textipa{\.*s}}} \\
 \begin{cjhebrew}.t\end{cjhebrew} (\textipa{\.*te\.*t}) & & \textipa{\textsuperimposetilde{t}}&  \textsf{\textipa{t}} & \textit{\textsf{\textipa{\.*t}}} \\
  \multirow{2}{*}{\begin{cjhebrew}t\end{cjhebrew} (\textipa{tav})} &  & \textipa{t} &  \textsf{\textipa{t}} & \textit{\textsf{\textipa{t}}} \\
& Vowel\,\_ & \textipa{T} &  \textsf{\textipa{t}} & \textit{\textsf{\textipa{t}}} \\
% \multirow{2}{*}{\begin{cjhebrew}b\end{cjhebrew} (bet)} & \multirow{2}{*}{Vowel\_} & \textipa{b} & \textsf{\textipa{b}} & \textit{\textsf{\textipa{b}}} \\
% &      	  & \textipa{B} & \textsf{\textipa{v}} & \textit{\textsf{\textipa{v}}} \\
 \multirow{2}{*}{\begin{cjhebrew}b\end{cjhebrew} (bet)} & & \textipa{b} & \textsf{\textipa{b}} & \textit{\textsf{\textipa{b}}} \\
		         & {Vowel\,\_} & \textipa{B} &\textsf{\textipa{v}} & \textit{\textsf{\textipa{v}}} \\
 \begin{cjhebrew}w\end{cjhebrew} (\textipa{waw}) & & \textipa{w} & \textsf{\textipa{v}} & \textit{\textsf{\textipa{w}}} \\
\bottomrule
\end{tabular}
\caption{Correspondences between Hebrew orthography, speech sounds (past and present), and the BLC's transcriptional system}
\label{tab:phon-neut}
\end{table}

\subsection{Morphological Annotation}
\label{sec:morph-annotation}
For our purposes, the most salient aspects the BLC's morphological 
annotation are those relevant to the tasks of
\begin{itemize}
\item extracting unified word tokens, each completely free of internal morphological 
delimiters or any other annotative device
\item extracting each word's corresponding morphological analysis from the 
\textsf{\%mor} tier, maintaining the one-to-one
correspondence between words and morphological analyses. 
\end{itemize} %are those that \citep{albert-et-al:2012}.
The morphological analyses themselves are essentially lists of morphological categories, 
i.e., lists of simple feature-value pairs.
The following is a BLC morphological analysis after undergoing the transformations 
described in section~\ref{sec:extr}:
\begin{exe} 
\ex \label{ex:finished}
\begin{tabbing}
\hspace{0.8in} \= \hspace{5.5in} \kill
\textsf{matxilim} \> \textsf{\textbf{matxil+im}\$\$part\&root:txl\&ptn:hifil\&gen:ms\&num:pl}\, \\
\> \textsf{\textbf{matxil+im}\$\$adj\&root:txl\&ptn:tbd\&gen:ms\&num:pl}
\end{tabbing}
\end{exe}
This example contains two separate analyses, a result of ambiguity. 
Each analysis is preceded by a segmentation (in boldface). 
In cases of ambiguity, i.e., of multiple analyses, each analysis gets its own 
segmentation, even though the segmentations may be identical.

\paragraph{Prefixal clitics.} In Hebrew, many functional words are 
\textit{prefixal clitics}; that is, they attach to content 
words as prefixes. They include the definite article \textit{ha-}, the prepositions 
\textit{le-} (`to, for') \textit{be-} (`in'), \textit{ke-} (`like/as'), and \textit{me-} 
(`from'), the  complementizer/relativizer \textit{\v{s}e-} (`that/which'), and the 
conjunction \textit{we-} `and.' For example,  in
\textsf{wehay\'eled} (`and the boy'), the prefixes \textit{we-} and \textit{ha-} 
are attached as clitics to \textit{y\'eled}, 
so that the whole is regarded as a single word. The 
BLC tokenizes these clitics, separating them from the 
main (content) word, and adding the number symbol (`\texttt{\#}') to 
the end of each prefixal clitic:
\begin{exe}
\ex  \textsf{wehay\'eled}  \quad $\mapsto$ \quad \textsf{we\# ha\# y\'eled}.
\end{exe}
%would be transcribed as \textsf{we\# ha\# y\'eled}.
The following example from the BLC, example~(\ref{ex:pphash2}), shows the morphological analyses accompanying the prefixal clitics \textit{we-} (`and') and \textit{\v{s}e-} (`that') as well as the morphological analysis of the main word.
% \textit{we-} (`and') followed by the complementer/relativizer \textit{\v{s}e-} (`that'), which is another prefixal clitic.  It also shows the corresponding morphological analyses.
\begin{exe}
	\ex 
	\textsf{we\#\, \v{s}e\# me\textipa{Q}arbev\'im} \\  \label{ex:pphash2}
	\textsf{conj|we conj:subor|\v{s}e\, part|\textipa{P}irb\'ev\&root:\textipa{Q}rbb\&ptn:piel\&gen:ms\&num:pl} 
\end{exe}

\paragraph{Demarcation of inflectional affixes.}
Past tense verbs take inflectional suffixes. Future-tense verbs take both inflectional prefixes and suffixes. 
Nominals, where inflection
is concerned, take only suffixes. The `\#' and `-' symbols are used to separate inflectional
affixes from the stem's morphological analysis; the `\#' used in the case of prefixes, `-' in the
case of suffixes, as in the following:

\begin{exe}
\ex \begin{tabbing} \label{ex:pre:v:suf}
\hspace{0.6in} \= \hspace{5.5in} \kill
\textsf{*CHI:} \> \textsf{tirt\a'{u} .} \\
\textsf{\%mor:} \> \textbf{\textsf{ti}\#}\textsf{v|ra\textipa{P}\a'{a}\&root:r\textipa{P}y\&ptn:qal\&tense:fut\&pers:2\&
\textbf{gen:unsp\&num:pl-\a'{u}}=see}
\end{tabbing}
\end{exe}

\paragraph{Compound and bound nouns}
Construct-state nouns are labeled either as ``\textsf{stat:bound}'' 
or ``\textsf{stat:comp}'' (i.e.,`compound'). 
These two labels correspond to the same sort of phonological form, 
 so I collapsed them into a single label, namely 
``\textsf{stat:cstr}'' (for `construct state').

\subsection{Anomalous Forms}\label{sec:anomolous}

Even though the BLC contains a good deal of adult speech, it also, 
of course, contains child speech, which  
can be rife with anomalies (anomalies relative to adult speech, that is). 
And while such anomalies are interesting if one is studying language acquisition 
in children, they are not helpful where the present study is concerned. It 
was therefore necessary to ``correct'' such anomalous forms where it was 
possible to do so, and discard them where it was not. Toward this end, 
the BLC's annotation conventions proved to be a great help.

\paragraph{Forms to be replaced}
The BLC deals with anomalous forms through a special 
annotative device consisting of a set of square brackets, with the left bracket 
accompanied
by a colon, i.e., 
\begin{center}
\textsf{[: \textit{corrected-form} ]}
\end{center}
Sometimes these brackets 
are followed by a second set of brackets, as in the following:
\begin{exe} \label{ex:tau}
\ex \textsf{tikri \,\textbf{[: tiqre\textipa{P}\a'{i}]}\, \textbf{[*]}\, sip\a'{u}r\, d\a'{o}da\, Orly .}
\end{exe}
This second set, if present, most frequently contains just an asterisk shown, as in example~(\ref{ex:tau}). However,
the asterisk may be followed
by an error classification. The first bracket pair (the one with colon) offers a correction for the preceding erroneous/anomalous form.

%However, since neither error categories nor errors were relevant to the present study, I discarded second bracket pair wherever it occurred, and I replaced anomalous/erroneous forms with their respective corrections.

% with the content in the first set of brackets ( %and was thus discarded. %discardethis second set of brackets was not
%(`*$\tau$') where $tau$ may be empty, or it may specify some error category. 
%In the BLC, it is most frequently empty. %, as in (\ref{ex:repl2}). 

%According to the CHILDES manual \citep{macwhinney:2000b}, the purpose 
%of the ``\textsf{[*$\tau$]}'' 
%is to specify that an anomalous form is 
%indeed erroneous rather than merely non-standard. 
%However, this distinction between 
%\textsf{[: \textit{corrected-form} ]} and 
%\textsf{[: \textit{corrected-form} ] [*{$\tau$}]} is not always manifest in BLC.
%In (\ref{ex:repl1}), the anomalous 
%form \textsf{patux} 
%(the `\textsf{@c} ' indicates a child-created form); 
%the anomaly is an absent \textsf{a} before the \textsf{x}, thus violating 
%a morphophonemic process 
%whereby \textit{a} is inserted before pharyngeals.\footnote{This is a process grandfathered in from
%from Classical Hebrew; its triggering context actually no longer exists, as Modern Hebrew no longer has pharyngeals (see section~\ref{tab:a-insertion}).}
%In (\ref{ex:repl2}), the error is essentially that the pre-\textit{\textipa{P}} 
%\textit{a} is absent. The glottal stop
%associated with the grapheme \begin{cjhebrew}'\end{cjhebrew} (\textit{'alef}) 
%is typically not articulated in Modern Hebrew \citep{montoya:2014}. The distinction
%between the two is not entirely clear.
%
%The distinction between , if there is one, is not important for our purposes. 
%Either way, I needed to replace the anomalous form with the form enclosed in 
%(the first pair of) brackets (see example~(\ref{ex:brackets})). We can just discard the \textsf{[*$\tau$]} 
%if it is present, regardless of what $\tau$ is.
%The important material for our purposes was between the first pair of brackets, as these brackets offer a correction of the preceding erroneous form. I replaced all erroneous forms with their respective corrections.
%\begin{exe}
%\label{ex:brackets}
%%\ex %\begin{xlist} 
%\ex\label{ex:repl1} 
%   %\ex\label{ex:repl1} 
%   \begin{tabbing}  
%  \hspace{0.6in} \= \hspace{5.5in} \kill
%  \textsf{*CHI:} \> \textsf{po ye\v{s} patux@c \textbf{[: pat\a'{u}ax]} d\a'{e}let .}
%  \end{tabbing}
%\end{exe}  
%     \ex\label{ex:repl2} \begin{tabbing}
%  \hspace{0.6in} \= \hspace{5.5in} \kill
%  \textsf{*CHI:} \> \textsf{tikri \,\textbf{[: tiqre\textipa{P}\a'{i}]}\, \textbf{[*]}\, 
%  sip\a'{u}r\, d\a'{o}da\, Orly .} \\
%  \textsf{\%mor:} \> \textsf{ti\#v|qar\a'{a}\textipa{P}\&root:qr\textipa{P}\&ptn:qal\&tense:fut\&pers:2\&gen:fm\&num:sg-\a'{i}=read} \\
%                    \> \textsf{n|sip\a'{u}r\&gen:ms\&num:sg\&stat:unsp } \\
%                    \> \textsf{n|dod\&gen:fm\&num:sg\&stat:free-a=uncle/aunt} \textsf{n:prop|Orly .}
%  \end{tabbing}
%   \end{xlist}
%\end{exe}


\paragraph{Dropped sounds}
The adults recorded in the BLC produced anomalous or non-standard speech, too. In example~(\ref{ex:dropped}), for instance, the investigator 
has dropped the 
\emph{n} from the infinitive form 
\textsf{li\textbf{(n)}s\'oa\textipa{Q}} (`to ride, drive, travel'), 
which is of the root \textit{n.s.\textipa{Q}}. 
The BLC's transcribers ``restored'' such dropped or deleted sounds and enclosed them in parentheses.
\begin{exe} 
\ex \label{ex:dropped} \textsf{li(n)s\a'{o}a\textipa{Q} \, ba\#\, \v{s}en\a'{i} ?}
\end{exe}

%\ex \begin{tabbing}
%\hspace{0.6in} \= \hspace{5.5in} \kill
%\textsf{*INV:} \> \textsf{li(n)s\a'{o}a\textipa{Q} \, ba\#\, \v{s}en\a'{i} ?}
%\end{tabbing}
%\end{exe}

\paragraph{Duplications}
Sometimes the BLC records speakers as having repeated a word or clitic, as in example~(\ref{ex:redundant}),
% (\ref{ex:redundant}), a prefixal clitic, 
%is duplicated, and sometimes repeated
%several times consecutively. 
The BLC records word repetiton (i.e., as part of dysfluency) even when it results in ungrammaticality.
%(as in a dysfluency), 
For example, (\ref{ex:redundant}) shows an utterance in which the prefixal clitic \textit{we\#} is 
attached to itself several times. No special annotation is used to mark or correct such repetitions. 
%Notice that morphological analysis for
%for \textit{we\#} is also repeated, so that each \textit{we\#} in the main tier has its ``own'' copy of the morphological analysis.
\begin{exe} 
\ex \label{ex:redundant} \textsf{*CHI:\quad we\# we\# we\# we\#\, nigm\textipa{\'a}r } \\
   \textsf{\%mor:\quad conj|we=and\, conj|we=and\, conj|we=and\, conj|we=and} \\
   \textsf{v|nigm\'ar\&root:gmr\&ptn:nifal\&tense:past\&pers:3\&gen:ms\&num:sg=be\_finished }
\end{exe}

%Observations: Note the number (or pound) sign \textsf{\#} at the end of the token \textsf{ba\#}. `in the', which is analyzed in the MA tier as $\texttt{prep|be}$$\sim$$\texttt{det|ha}$. 
%We handle this in different ways in the transcriptions vs. the morphoplogical analyses. Within the 
%morphological analysis tier, the analyses are delimited by spaces, with each single analysis corresponding
%to a word in the transcriptional tier. 
 
\section{Extracting the Input Datasets}
\label{sec:extr}
%To conduct the experiments, three input wordlists were necessary, 
The experiments required three input wordlists, one for each data-representation type. 
namely, a transcriptional list with stress markings (TS), a transcriptional list without stress markings  (TR), and an orthographic list (O).
The words in TS were composed of the BLC's transcriptional symbols, 
whereas those in O
were composed of regular Hebrew letters, following Hebrew spelling conventions. 
In O, the standard Hebrew letters were converted to ASCII characters in a one-to-one
mapping, namely the transliteration mapping of the Hebrew Treebank 
\citep{simaan-et-al:2001}, displayed in table~\ref{tab:ortho-alph}). %adgdhwzxviklmnsypcqret
\begin{table}[ht]
\setlength{\extrarowheight}{8pt}
\centering
\caption{Romanization of the Hebrew Alphabet \citep{simaan-et-al:2001}}
\label{tab:ortho-alph}
\begin{tabular}{c c c c c c c c c c c}
\toprule %\hline                      
\begin{cjhebrew}'\end{cjhebrew} & \begin{cjhebrew}b\end{cjhebrew} & \begin{cjhebrew}g\end{cjhebrew} & \begin{cjhebrew}d\end{cjhebrew} 
& \begin{cjhebrew}h\end{cjhebrew} & \begin{cjhebrew}w\end{cjhebrew} & \begin{cjhebrew}z\end{cjhebrew}& \begin{cjhebrew}.h\end{cjhebrew}
& \begin{cjhebrew}.t\end{cjhebrew} & \begin{cjhebrew}y\end{cjhebrew} & \begin{cjhebrew}k|\end{cjhebrew} \\ 
a & b & g & d 
& h & w & z & x & v & i & k \\[12pt]
\midrule
%& \textsubdot{t} & y & k/\textsubdot{k} & l & m \\[12pt]
 \begin{cjhebrew}l\end{cjhebrew} & \begin{cjhebrew}m\end{cjhebrew} &
           \begin{cjhebrew}n|\end{cjhebrew} & \begin{cjhebrew}s\end{cjhebrew} & \begin{cjhebrew}`\end{cjhebrew} 
           & \begin{cjhebrew}p|\end{cjhebrew} & \begin{cjhebrew}.s\end{cjhebrew} & \begin{cjhebrew}q\end{cjhebrew} & \begin{cjhebrew}r\end{cjhebrew} & \begin{cjhebrew},s\end{cjhebrew}/\begin{cjhebrew}+s\end{cjhebrew} & \begin{cjhebrew}t\end{cjhebrew} \\
          l & m &
	n & s & y & p & c & q & r & e & t \\
\bottomrule
\end{tabular}
\end{table}
O was obtained by mapping each transcriptional representation 
in TS onto an orthographic representation. For example, \textipa{hitkawanti}$_{TS}$ $\to$
\textipa{htkwnti}$_{O}$ and \textipa{katavti}$_{TS}$ $\to$ \textipa{ktbti}$_{O}$. 
The TR words were obtained by 
replacing the accented vowel characters in the TS list with their unaccented counterparts.
Also necessary were three sets of morphological segmentations, one for each dataset: %namely $\text{T}_{SEG}$ and $\text{O}_{SEG}$, where:
\begin{itemize}
\item $\text{TS}_{SEG}$ = segmentations for 10 percent of the words in TS.
\item $\text{TR}_{SEG}$ = $\text{TS}_{SEG}$, except with the accented vowels replaced
with unaccented vowels.
\item  $\text{O}_{SEG}$ = segmentations for 10 percent of the words in O.
\end{itemize} 
%A third set of segmentations TR
%Each acted as a gold-standard in the extrinsic 
%component of the evaluation phase. (see chapter \ref{ch:eval}).  

\paragraph{Replacement of Anomalous Forms.} 
The input datasets were extracted from the BLC. However, as noted above in 
section~\ref{sec:anomolous}, the BLC is by no means free of anomalous forms, 
forms that are ungrammatical with respect to the standard form of the language, 
forms that, for our purposes, would convey misinformation about the language if taken at face value. 
Such misrepresentative and potentially misleading forms were excluded from the 
extracted input data.  
Wherever a pair of brackets, i.e., \textsf{[: \textit{corrected-text} ]}, was encountered, 
the material within the brackets was extracted in place of the anomalous word (i.e., the 
word the preceding the ``\textsf{[:}'').

\begin{exe}
	\ex Replacing anomalous forms with their bracket-enclosed corrections
	\begin{xlist} \label{ex:replace}
	   \ex \textsf{*CHI:}\quad\textsf{po\, ye\v{s}\, \textbf{patux@c\, [: pat\'{u}ax ]}\, d\'{e}let} $\quad\to\quad$
	   \textsf{po ye\v{s} \textbf{pat\'{u}ax} d\'{e}let} 
	   \ex \textsf{*CHI:}\quad\textsf{\textglotstop\'{o}\textsubdot{t}o\, \textbf{micpacef@c}\, \textbf{[: mecafc\'ef ]\, [*]}} $\quad\to\quad$ \textsf{\textglotstop\'o\textsubdot{t}o\, \textbf{mecafc\'ef}}
	\end{xlist}
\end{exe} 

\paragraph{Prefixal clitics.}
Whenever a word in the main tier was preceded by one or more prefixal clitic, the entire sequence of clitics were concatenated together, and the resulting string was then attached  to the base word. All ``\texttt{\#}'' symbols were discarded, as in the following:
\begin{exe}\label{ex:preclitics}
	\ex
	\textsf{we\#\, \v{s}e\# me\textipa{Q}arbev\'im} $\quad\to\quad$ \textbf{\textit{\textsf{we\v{s}e}}}\textsf{me\textipa{Q}arbev\'im}\\
	\textsf{conj|we conj:subor|\v{s}e\, part|\textipa{P}irb\'ev\&root:\textipa{Q}rbb\&ptn:piel\&gen:ms\&num:pl} $\quad\to\quad$  \\
	\textit{\textbf{\textsf{conj:we\&conj:subor:sh\&}}}\textsf{part|\textipa{P}irb\'ev\&root:\textipa{Q}rbb\&ptn:piel\&gen:ms\&num:pl}
\end{exe}

\paragraph{Complex adverbs.} In the BLC, all adverbs are characterized as atomic, unanalyzable morphological units. That is,
the analysis any adverb, no matter how morphologically complex, is simply ``adv'', as in 
examples (\ref{ex:adv:bediyuq}) and (\ref{ex:adv:dscr})  These show the BLC's treatment of the adverbs \textit{\textsf{bediy\'{u}q}} and \textit{\textsf{me\textglotstop{a}xoran\'{i}t}}, respectively. Both are 
morphologically complex.

\begin{exe}
\ex \label{ex:adv:bediyuq}
	\begin{tabbing}
	\hspace{0.6in} \= \hspace{5.5in} \kill
	\textsf{*INV:} \> \textsf{ken ze \textbf{bediy\a'{u}q} xat\a'{u}l .} \\
	\textsf{\%mor:} \> \textsf{co|ken=yes\, pro:dem|ze\&pers:3\&gen:ms\&num:sg=it/this} \\
				\> \textsf{\textbf{adv|bediy\a'{u}q=exactly/precisely}} \\
				\> \textsf{n|xat\a'{u}l\&gen:ms\&num:sg\&stat:unsp=cat .}
	\end{tabbing}
\ex \label{ex:adv:dscr}
	\begin{tabbing}
	\hspace{0.6in} \= \hspace{5.5in} \kill
	\textsf{*INV:} \> \textsf{\textglotstop{i}\_{\textglotstop}{e}f\v{s}\a'{a}r \, raq \, \textbf{me\textglotstop{a}xoran\a'{i}t}\, 
		nto@c\, h@c .} \\
	\textsf{\%mor:} \> \textsf{adv|{\textglotstop}i\_{\textglotstop}ef\v{s}\a'{a}r=impossible \, adv|raq=only}\\
	 \> \textsf{\textbf{adv|me{\textglotstop}axoran\a'{i}t=from\_behind}\, chi|nto\, chi|h .}
	\end{tabbing}
\end{exe}

The adverb \textit{bediy\'uq} (`precisely, exactly')
is composed of the prefixal preposition \textit{be-} (`in') and the 
noun \textit{diy\'uk} (`exactitude, accuracy'), which is itself composed of the 
root %$\surd$
\textit{d.y.q} and the nominal vowel pattern C\textbf{i}C\textbf{\'u}C 
a pattern that implies a relationship to a verb of the \textit{Pi`el} binyan.  
The adverb \textit{\textsf{me\textglotstop{a}xoran\'{i}t}} in 
(\ref{ex:adv:dscr}) is even more complex. It has two nominalizing
derivation affixes \textit{\textsf{-an}} and \textit{\textsf{-it}} in addition 
to the prefixal preposition \textit{\textsf{me/i-}}. Moreover, it contains the 
root \textit{\textipa{P}.x.r}, %$\surd$\textsf{\textipa{P}.x.r}, 
which is generally associated with meanings 
related to `late' and `after'.

I thus expanded the morphological analyses of complex adverbs in order to capture at 
least some of the derivational morphology of these adverbs.
%T morphological analyses of complex adverbs were expanded.
But I did not go so far as to delineate morphomes, as this would 
be straying too far from the rest of the analyses in the BLC. Such 
analyses would be out of place among all of the other analyses in corpus. 
This would at best be a futile, and at worst, experimentally detrimental.

The expansion of adverb analyses thus consisted of the following limited set of actions. 
\begin{enumerate}
\item If the adverb in question is a noun to which a prefixal preposition is attached, e.g., \textit{be-diy\'uq} (\textit{be} `in' + \textit{diy\'uq} `exactitude' = `exactly'),  %(for such combinations often constitute adverbs),
analyze it as noun bearing a prefixal preposition, not as an adverb. (In general, prefer lower-level, more primitive analyses to higher-level,
more interpretative ones.) 
\item Otherwise: %, identify any prefixal prepositions that contribute to the adverb's form.
    \begin{enumerate}
        \item Identify any prefixal prepositions that contribute to the adverb's form.
        \item Specify the \emph{root}, if any is present.
        \item Specify the \emph{vowel pattern}, if any is present. (Generally, if there is a root, there will be a vowel pattern.) 
    \end{enumerate}
\end{enumerate}

\paragraph{Compound nouns.}
Compound nouns in both Classical Hebrew and Modern Hebrew are made up of a \emph{chain} of 
one or more nouns in the \emph{construct} state followed by a final noun
in the \emph{absolute} state. The former is marked by reduced stress 
and the latter by a normal stress assignment. The following examples 
illustrate the way compound nouns are treated in the BLC.
\begin{exe}
\ex \label{ex:cstr:pasey}
	\textsf{pas\'{e}y+ha+rak\textipa{\'{e}}vet} \\
	\textsf{n:det|+n|pas\&gen:ms\&num:pl\&stat:comp-\'{e}y+det|ha+n|rak\textipa{\'{e}}vet}
\ex \label{ex:cstr:shaat} 
	\textsf{\v{s}\textglotstop{at}+sip\'{u}r .} \\
	\textsf{n|+n|\v{s}a\textipa{Q}\'a\&gen:fm\&num:sg\&stat:comp-\'at+n|sip\'ur .}
\ex \label{ex:cstr:bdiqat} 
	\textsf{bdiq\'{a}t+\textipa{P}ozn\'{a}yim} \\ 
	\textsf{n|bdiq\'{a}\&root:tbd\&ptn:tbd\&gen:fm\&num:sg\&stat:bound-\'{a}t}
\end{exe}
In the main tier (i.e., the transcription tier), the components of a compound noun are
delimited by the `+' symbol. 

A compound noun consists of at least two nouns. One of these 
(and only one) is the head of compound, that is to say, that it carries 
the morphosyntactic features of the whole compound. In a Hebrew compound 
noun, the first noun
is always the morphosyntactic head, despite its phonologically 
reduced state.
Thus, in (\ref{ex:cstr:pasey}), \textsf{pas\'{e}y} `stripes/bands' 
is the head of \textsf{pas\'{e}y+ha+rak\'{e}vet} `the railroad 
tracks.'\footnote{The \textit{ha} at the beginning of  
\textsf{\textit{ha}rak\'{e}vet} is the definite article, a prefixal 
clitic. The definite-article clitic attaches not to the compound's 
morphosyntactic head, but rather to its \emph{phonological} head, 
i.e., the final component noun, which bears the compound's primary stress.}

For our purposes, we needed to extract only the first noun of a compound noun, 
discarding all others.
There are two reasons for doing this:
The first is word length; 
i.e., compound nouns can, in principle, be indefinitely long and comprise
indefinitely many component nouns.
%\marginpar{What is the longest in the data?} 
Even a compound of two nouns begins to exceed the scope 
of a ULM study. It is challenge enough 
to identify a single 
content stem or a single content root in a word. 
The second reason concerns the distribution of features among the 
component nouns: Because the initial noun is the head, its 
features are \emph{the same as} the features of the whole compound. 
The means that we only have to extract the morphosyntactic 
features of the initial noun to extract the features of the whole 
compound. In fact, the other nouns in the compound will be 
morphosyntactically empty. They still have morphology, of course, 
but this sort of morphology is not annotated in 
the BLC. The BLC provides only morphosyntactic 
features, which are the morphosyntactic features of the initial 
noun. There is nothing else to extract where compound nouns 
are concerned.

\begin{exe}
\ex \label{ex:cstr:pasey2}
	\textsf{pas\textipa{\'{e}}y+ha+rak\textipa{\'{e}}vet} $\quad\to\quad$ 
	\textbf{\textsf{pas\textipa{\'{e}}y}} \\
	\textsf{n:det|+n|pas\&gen:ms\&num:pl\&stat:comp-\'{e}y+det|ha+n|rak\textipa{\'{e}}vet} $\quad\to\quad$ \\
	\textbf{\textsf{pos:n\&gen:ms\&num:pl\&stat:cstr}}
\ex \label{ex:cstr:shaat2} 
	\textsf{\v{s}\textglotstop{at}+sip\'{u}r} $\quad\to\quad$ \textbf{\textsf{\v{s}\textglotstop{at}}}\\
	\textsf{n|+n|\v{s}a\textipa{Q}\'a\&gen:fm\&num:sg\&stat:comp-\'at+n|sip\'ur} $\quad\to\quad$ \\
	\textbf{\textsf{pos:n\&gen:fm\&num:sg\&stat:cstr}}
\ex \label{ex:cstr:bdiqat2} 
	\textsf{bdiq\'{a}t\, \textipa{P}ozn\'{a}yim} $\quad\to\quad$ \textbf{\textsf{\textsf{bdiq\'{a}t}}} \\ 
	\textsf{n|bdiq\'{a}\&root:tbd\&ptn:tbd\&gen:fm\&num:sg\&stat:bound-\'{a}t} $\quad\to\quad$ \\
	\textbf{\textsf{pos:n\&root:tbd\&ptn:tbd\&gen:fm\&num:sg\&stat:cstr}}
\end{exe}

\paragraph{Other multiword expressions} Sometimes one encounters two or more words joined 
by an underscore character. These are multiword expressions. We exclude them from
the input datasets. 
\begin{exe}
\ex \begin{tabbing}
\hspace{0.6in} \= \hspace{5.5in} \kill
\textsf{\*MOT:}\>\textsf{kol\_ha\_kav\a'{o}d .} \\
\textsf{\%mor:} \> \textsf{co|kol\_ha\_kav\a'{o}d=well\_done}
\end{tabbing}
\end{exe}


\section{Experimental Variables}\label{sec:expvars}
The experimental component of this thesis consists of two major axes of inquiry. 
One concerns the \textsc{representation} of the input data, and the other the \textsc{features}. 
We shall address each of these in turn. 

In chapter~\ref{ch:intro}, we discussed the problem of choosing a feature set. 
We described it as a problem of selecting one finite subset of 
features from an infinite number of possible features.
We shall now revisit this question. Our approach 
will be to think in terms of feature categories, i.e., to define categories of 
features that have favorable properties. We shall also take into account 
the properties of our learning framework, namely the bipartite graph. We shall thus discard feature types 
(or categories) that are at odds with this learning framework. (For example, global features are not well suited to
the nature of the bipartite graph; see section~\ref{sec:features} for an explanation.)
Ultimately, we cannot consider every 
possible feature or feature set. What we can do is produce some 
principled candidate feature sets with which to experiment. 

We shall glean considerable insight from the field of computer vision. 
That is, we shall consider feature 
categories that are significant to computer vision, doing so with an 
eye to adapting them for the purposes of ULM. The idea is that it
is actually a very general problem, and thus the same types of features 
sometimes should apply to different types of objects.
We shall focus in particular on \emph{invariant} and \emph{variant} 
features. The distinction between these two feature types is highly significant in
computer vision and its various subfields. In the present thesis, 
we hypothesize that this distinction is also relevant to ULM. 

\subsection {Data Representation} 
\label{sec:datarep}
By \emph{representation} we mean the alphabet whose 
symbols compose the strings (i.e., words) 
of an input wordlist.
In the present work, three data representations were tested, two transcriptional 
(TS and TR), and one orthographic (O), as described above.
TS consisted of the BLC's transcriptions, and TR was TS without the stress markings. 
%Its alphabet is thus the BLC's 34-symbol
%transcriptional system, which we discussed above in section.
O consists of TS's words, but mapped onto orthographic 
representations; every character in O is thus
a letter of the 22-letter consonantal Hebrew alphabet.
Arguably, the transcriptional datasets contains more information than O,
since TR and TS each has a dedicated symbol for each of Modern Hebrew's five vowels sounds (TS in fact has two symbols for each vowel, one stressed and one unstressed),
as well as all of the archaic consonantal distinctions found in O. 
%\textsc{data representation} refers to the ``encoding'' of the input
%word lists. Essentially, it refers to a choice between one of two alphabets (and the spelling conventions that 
%accompany each alphabet). The two alphabets are the standard consonantal Hebrew alphabet, consisting of 22 letters,
%and the 34-symbol BLC transcriptional system.]

\subsection{Features}   %\label{sec:expvars:features}
\label{sec:features}

\subsubsection{Feature-set Desiderata: Insights from Computer Vision}
\paragraph{Invariance vs. Variance.}
\cite{dudani-et-al:1977} describe three desiderata for features in the 
domain of aircraft identification:
\begin{quote}
\begin{enumerate}
\item The features should be informative. That is, the dimensionality of a 
vector of measurements (feature vector) should be as low as possible, 
consistent with acceptable recognition accuracy.
\item The features should be invariant with translation of the object 
normal to the camera optical axis and with rotation about this axis.
\item The features should either be invariant or depend in a known 
way upon the distance of the object from the camera.
\citep[][p. 40]{dudani-et-al:1977}.
\end{enumerate}
\end{quote}
Though stated in terms of computer vision and image recognition, 
these desiderata (or criteria) are relevant to all varieties of machine 
learning and clustering, including, of course, what Multimorph does, which is to
cluster words according to shared components.

Two types of features used in computer vision are \emph{variant} and \emph{invariant} features.
The former are sensitive to context and thus change as their context changes, whereas
the latter remain constant regardless of context.
Invariant features are generally considered to be preferable to variant 
features \citep{hossain-et-al:2012}. 
There are different kinds of invariance for different kinds of problems.
\emph{Scale} and \emph{rotation} invariance are just two examples. If a feature 
is scale-invariant, its
value is independent of the size of the object in question. That is, a 
scale-invariant feature
can have the same value for objects $A$ and $B$, regardless of the 
relative sizes of $A$ and $B$. $A$ could be much larger than $B$, for instance, or much smaller,
but in either case, a scale-invariant feature would be oblivious, so to speak, to the difference in size. 
This is important because $A$ and $B$ could in fact be the one and the same object; it might appear 
larger in one photograph simply because 
it was closer to the camera when that photograph was taken.

Sometimes, however, both invariant and variant features are necessary, 
as in optical character recognition\citep{trier-et-al:1996}.
%For example, in the field of optical character recognition
%provides some good examples of this scenario. 
Rotation-invariant features are considered essential in optical character recognition \citep{trier-et-al:1996}, 
at least
insofar as a character's identity is independent 
of its orientation.
And indeed, the identities of most Roman letters, both upper and lower case, are invulnerable to rotation.
For example, if the letter \textsf{A} is rotated 180 degrees, it remains 
recognizable as an \textsf{A}, since its distinguishing features do not change when it is rotated. 

 
However, this is not true of all letters. In many type faces, for instance, 
\textsf{q} can be rotated to become \textsf{b}, and \textsf{u} can be rotated to 
to become \textsf{n}. Often, a rotated (upside-down) \textsf{M} closely 
resembles a \textsf{W}. And should we consider numerals, we would have to deal 
with the famously rotation-variant \textsf{6} and \textsf{9}. If an 
optical-character-recognition system were to rely solely upon rotation-invariant features, it
would not be able to distinguish between, for instance, \textsf{6} and 
\textsf{9}, since the only features that can distinguish \textsf{6} from \textsf{9}
are rotation-variant.

\paragraph{Global vs. Local Features.}
Global features describe an image as a whole, whereas local features are concerned
only with a particular region in the image. That is, the value of local feature is dependent
only upon its particular region; it is not affected by other regions. 
In optical character recognition, an example of a global feature is \emph{aspect ratio}, defined 
as the width of a character's rectangular bounding box divided by the same 
box's height. Note that aspect ratio is size-invariant. Global features 
can be made invariant 
through normalization, and ratios are a means of normalization.

A global feature for ULM could be the number 
of characters in a given word, which could be binned. Another 
could be the consonant-to-vowel ratio in a word. The question, however, is 
whether such properties are relevant and beneficial to Multimorph's task,
which is to group together words that share rather specific formal (i.e. form-based) components. 

The main problem with global features where the present study is concerned is that
words tend to be complex objects, often composed of 
multiple morphological units, which are 
generally orthogonal. That is, a plural suffix can 
appear with a wide variety of stems, for example, and a 
given stem may occur with a wide variety of suffixes.
Two words can share a single morphological component and 
differ in the rest of their components. Indeed,
they can be more different than they are alike from a cumulative, 
quantitative point of view. Nevertheless,
as far as that one shared component is concerned, these two are 
\emph{the same} and thus co-members of a morphological
class. 

Moreover, gobal features do not really fit the bipartite learning framework.
As shown in chapter~\ref{ch:graph}, an MCMM is a bipartite graph and thus 
satisfies the following:
\begin{enumerate}
\item Its nodes are separated into two disjoint sets (or partitions).
\item Within each partition, all nodes are independent, i.e., mutually 
nonadjacent.
\end{enumerate}
%In an MCMM, the two partitions are the vectors $\textbf{m}_{i}$
%and $\textbf{r}_{i}$ (for each word $i$). The former is the vector of 
% cluster activities, and the latter
% is the \emph{reconstruction} of word $i$'s original 
% feature-vector representation of word. Recall from chapter~\ref{ch:MCMM}, 
% specifically section~\ref{sec:architecture}, that $\textbf{r}_i$ is the (working)
% reconstruction of $\textbf{x}_i$, which is both original and the target feature vector for word $i$ (i.e., since the goal is to reconstruct the original words given the (working) hidden-unit vector for each word,
By the definition of \emph{bipartite}, therefore, \emph{every} feature in an MCMM $\textbf{r}_i$ is independent,
and thus every feature is local. 

%Global features do not seem well-suited to represent this kind of modular similarity. 
For these reasons, global features were not tested in this study. All features were local. 


\subsubsection{(In)variant Features for Morphological Learning}
\label{sec:invariant-features}

On the other hand, the invariant \emph{vs.} variant distinction was a focal point in this study. The kind of invariance at issue in this study was \emph{affixation-invariance}. The value of an affix-invariant feature does not change when affixes are attached to the beginning or end of a word. Two main feature types were tested, namely a \emph{positional features}, which are affixation-\emph{variant}, and \emph{precedence features}, which are affixation-invariant.

\paragraph{Positional Features.}
Positional features
indicate the presence of a particular
character at a certain position relative to either the beginning or the end of 
a word. For example, \texttt{i@[0]} indicates that \textit{i} is the first 
character, while \texttt{i@[-1]} indicates that \textit{i} is the last character. 
Indices relative to the beginning are non-negative, while those relative 
to the end are negative. In any case, the number of positions considered 
at the beginning is always equal to the number at the end. This number, 
$s$, is an experimental variable.
the variable $s$ is equal to the absolute value of the smallest negative index. 
For example, $s=4$ means that for each character $\alpha$, the following 
features are generated: $\alpha$\texttt{@[0]}, $\alpha$\texttt{@[1]}, 
$\alpha$\texttt{@[2]}, $\alpha$\texttt{@[3]}, $\alpha$\texttt{@[-1]}, $\alpha$\texttt{@[-2]}, 
$\alpha$\texttt{@[-3]}, $\alpha$\texttt{@[-4]}.
That is, we count three positions inward from each word boundary.
Positional features are \emph{variant} 
with respect to affixation, which is to say that positional features are 
defined relative to the absolute beginning 
or end of a given word. 

\paragraph{Precedence Features.}
Precedence features indicate, for any two characters $x$ and $y$,
whether $\alpha$ precedes $\beta$ within $\delta$ characters,
where $\delta$ is an experimental variable defined as
	\begin{equation}\label{eq:indexdif}
	\delta = \text{index}(\beta) - \text{index}(\alpha)
	\end{equation}
Note that if $\delta = 1$, the precedence features are 
pairs of adjacent characters, i.e., bigrams.
Precedence features are invariant with respect to affixation; that is, 
they are \emph{affixation-invariant}.
As an example, consider again the word
\begin{center}
\textit{we\v{s}eme\textipa{Q}arbevim} \quad `and which confuse'
\end{center} 
%whose BLC morphological 
%analysis appears above in example (\ref{ex:preclitics}). 
This word has has \textbf{two prefixal clitics}, namely \textsf{we} 
(`and') and \textsf{\v{s}e} (`which').
Suppose $\delta=2$. The feature \textsf{b<v} then would be assigned the value $1$ with respect to
\textit{we\v{s}eme\textipa{Q}arbevim}, since
\begin{equation*}
\text{index}(\text{b}) - \text{index}(\text{v}) = 11 - 9 = 2
\end{equation*}
which satisfies the criterion `less than or equal to $\delta$'. 
The feature \textsf{\textipa{Q}<b}, by contrast, would get the value $0$, since 
\begin{center}
\text{index}(\textipa{Q})\,$ - $\,\text{index}(\text{b})\,\,$ = 9 - 6 = 3$
\end{center}
which is greater than $\delta$ in this case.
Now consider the same main word \textit{me\textipa{Q}arbevim} \textbf{without}
the two prefixal clitics. Even though \textit{me\textipa{Q}arbevim} is four characters shorter than
\textit{we\v{s}eme\textipa{Q}arbevim}, the values of the features \textsf{b<v} and
\textsf{\textipa{Q}<b} do not change. That is,
%\begin{tabular}{ccc}
%Feature & $\text{index}(\text{\beta}) - \text{index}(\text{\alpha})$ & Value
%\end{tabular}
\begin{equation*}
\text{index}(\text{b}) - \text{index}(\text{v}) = 7 - 5 = 2   
\end{equation*}
which is still `less than or equal to $\delta$', and thus \textsf{b<v} is still $1$.
The feature \textsf{\textipa{Q}<b}, by contrast, would get the value $0$, since 
\begin{center}
\text{index}(\textipa{Q})\,$ - $\,\text{index}(\text{b})\,\,$ = 9 - 6 = 3$
\end{center}
which is still greater than $\delta$, and thus \textsf{\textipa{Q}<b} is still $0$.
%The others evaluate to 1 because the difference between indices in their cases is \emph{at most} 2. That is,
%\begin{exe}
%    \ex \begin{xlist}
%	\ex $\text{index}($\textsf{v}$) - \text{index}($\textsf{b}$) = 11 - 9 = 2$ 
%	\ex $\text{index}($\textsf{v}$) - \text{index}($\textsf{e}$) = 11 - 10 = 1$ 
%	\ex $\text{index}($\textsf{r}$) - \text{index}($\textsf{\textrevglotstop}$) = 8 - 6 = 2 $
%    \end{xlist}
%\end{exe}
%
%\begin{exe}
%    \ex \begin{xlist}
%	\ex $\text{index}($\textsf{v}$) - \text{index}($\textsf{b}$) = 7 - 5 = 2 \quad\to\quad $ \textsf{b<v} $ =1 $
%	\ex $\text{index}($\textsf{v}$) - \text{index}($\textsf{e}$) = 7 - 6 = 1 \quad\to\quad $ \textsf{e<v} $ =1 $
%	\ex $\text{index}($\textsf{r}$) - \text{index}($\textsf{\textrevglotstop}$) = 4 - 2 = 2 \quad\to\quad $\textsf{\textipa{Q}<r} $ =1 $
%	\ex $\text{index}($\textsf{b}$) - \text{index}($\textsf{\textrevglotstop}$) = 5 - 2 = 3 \quad\to\quad $ \textsf{\textipa{Q}<b} $ =0 $ 
%    \end{xlist}
%\end{exe}
Precedence features are thus not bound to absolute character positions, i.e., 
absolute indices. They are not defined relative to fixed points such as 
the beginning or end of a word.

\section{Experimental Program}
%The experiments tested different combinations of $s$ and $\delta$ values, 
%in particular for
%$s = \{0,2,4,6\}$ and $\delta = \{1,2,3\}$. Twelve features sets were derived from combining these $s$ and $\delta$ values:
%$\langle s = 0, \delta =1 \rangle$,  $\langle s = 0, \delta = 2 \rangle$, and so on.
%Each $\langle s, \delta \rangle$ pair corresponds to a distinct feature set that was tested in a particular experiment. 


For the transcriptional data types (TS and TR), the possible $s$ values were $s_T = \{0,2,4,6\}$, However, for O, they were different, namely $s_O = \{0,1,2,3\}$, since the O words contained fewer characters. All three data-representation types had the  same $\delta$ values, namely $\delta = \{1,2,3\}$. %Twelve features sets were 
To obtain the list of experiments, each $s$ and $\delta$ combination was paired with each of the three data-representation types, making sure to match the O data type only with the $s_O$ values, and likewise, the TS and TR data types only with the $s_T$ values. The result was a set of triples, each of which corresponded to an experiment. 

%derived from combining these $s$ and $\delta$ values:
%$\langle s = 0, \delta =1 \rangle$,  $\langle s = 0, \delta = 2 \rangle$, and so on.
%Each $\langle s, \delta \rangle$ pair corresponds to a distinct feature set that was tested in a particular experiment. 
%Each combination of $s$ and $\delta$ values was paired with each of the three data representation types, namely, the transcriptions with stress marking (TS), the transcriptions without stress marking, (TR), and the orthographic data (O).
%That is, Multimorph was run on each dataset at each of the feature-parameter combinations.  
%representations of the input data. 
%Two of these data representations were quasi-phonemic transcriptions---one with stress marking and one without. We shall abbreviate these two as TS and TR, respectively. The third kind of input-data representation was not transcriptional, but orthographic (O). 

\section{Summary}

This study involves three main experimental variables. Two are the feature parameters, namely, affix length $s$ and precedence span $\delta$. The third variable is the representation of the input data. Three data sets were used in the experiments. Two were transcriptional---one with stress marking and one with no stress marking, and the other was orthographic. The latter two types were derived from the transcriptional data with stress marking. 

Two feature types were chosen for experimentation. One of these two, namely the \emph{positional}  feature type, is \emph{variant} with respect to affixation, while the other, namely the \emph{precedence} feature type, is affixation-\emph{invariant}. 
%and the other invariant (with respect to affixation).\emph{positional features} and \emph{precedence features},
%because the former is variant and the latter invariant with respect to affixation. 
For example, if a prefix is represented only with positional features, its feature-value representation will change when another prefix is attached before it. Thus, the same prefix may have different feature-value representations in different words. Precedence features, on the other hand, are defined in such a way that they are unaffected when additional material is attached to the fronts or ends of words. However, this does not mean that precedence features are going to be better than positional features in every case. Some morphological units may require positional features, just as the characters \textsf{6} and \textsf{9} require position-variant features in optical character recognition. 

The focus of the next chapter will be the methods of evaluating the results of the experiments. We shall see why, for instance, we needed to extract not just the words from the BLC, but their morphological analyses as well.